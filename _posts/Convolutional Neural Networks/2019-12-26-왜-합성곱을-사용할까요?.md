---
layout: post
title: "왜 합성곱을 사용할까요?"
tags: [convolutional neural network, parameter sharing, sparsity of connection]
categories: [Convolutional Neural Networks]
---

# 학습 목표
- 왜 합성곱 신경망을 사용하는 것이 유용한지 배운다.

# 핵심 키워드
- 합성곱 신경망
- 변수 공유
- 희소 연결

# 학습 내용
- 합성곱 신경망을 사용하면 변수를 적게 사용할 수 있습니다.
  - 예를 들어, 32 * 32 * 3 이미지를 5 * 5 필터 6개를 통해 28 * 28 * 6의 이미지로 합성곱 연산을 했을 경우, 필요한 변수의 개수는 5 * 5 * 3 * 6 + 6 = 456 하지만 일반적인 신경망으로는 3072 * 4704 + 4704, 약 1400만개의 변수가 필요합니다.
- 합성곱 신경망이 이렇게 적은 변수를 필요로 하는 이유 중 하나는 변수 공유 입니다. 즉, 어떤 한 부분에서 이미지의 특성을 검출하는 필터가 이미지의 다른 부분에서도 똑같이 적용되거나 도움이 됩니다.
- 다른 하나의 이유는 희소 연결입니다. 즉, 출력값이 이미지의 일부에 영향을 받고, 나머지 픽셀들의 영향을 받지 않기 때문에, 과대적합을 방지할 수 있습니다.
- 합성곱 신경망은 이동 불변성을 포착하는데도 용이합니다. 즉, 이미지가 약간의 변형이 있어도 이를 포착할 수 있습니다.

# 인트로
왜 신경망에서 합성곱을 사용하는 것이 유용한지 살펴볼 것이고 마지막으로 이것들을 전부 조합하는 것과             
훈련 세트가 있을 때 합성곱 신경망을 훈련하는 법을 살펴볼 것입니다            
완전 연결 층 대신 합성곱 층을 사용할 때 두 가지의 이점이 있는데  바로 변수 공유와 희소 연결입니다            

# 예시
![image](https://user-images.githubusercontent.com/50114210/71471255-46c41780-2812-11ea-9684-96f387cd1b58.png)                    
예시로 보여드리겠습니다 32 x 32 x 3 크기의 이미지가 있다고 해봅시다            
사실 이전 영상에서 본 예인데 이번에는 6 개의 5 x 5 필터를 사용하면 28 x 28 x 6 크기의 출력을 얻게 됩니다            
32 x 32 x 3 은 3,072 고 28 x 28 x 6 을 전부 곱하면 4,704 입니다            
만약 신경망을 형성할 때 3,072 개의 유닛을 한 층에 두고  4,704 개의 유닛을 다음 층에 둔 다음            
각각의 뉴런들을 모두 연결하면 가중치 행렬의 변수의 개수는 3,072 x 4,704 개가 되고 1400만 개 정도가 됩니다            
훈련하기에 변수의 개수가 상당히 많죠            
오늘 날에는 1400만 개보다 더 많은 수의 변수도 훈련시킬 수 있긴 합니다            
그러나 이 이미지는 굉장히 작기 때문에 훈련하기에는 변수의 개수가 많죠            
그리고 만약 이 이미지의 크기가 1000 x 1000 이었다면 가중치 행렬이 실행 불가능할 정도로 커질 것입니다            
이 합성곱 층의 변수의 개수를 한 번 살펴보면 각 필터는 5 x 5 이어서 25 개의 변수를 가지고            
편향 변수를 더하면 필터 당 26 개의 변수를 가지게 됩니다            
그리고 6 개의 필터가 있기 때문에 총 변수의 개수는 156 개가 되죠            
그래서 합성곱 층의 변수의 수가 여전히 작게 유지됩니다            

# 변수 공유
![image](https://user-images.githubusercontent.com/50114210/71471270-54799d00-2812-11ea-9c64-e7f04795dbdc.png)              
합성곱 신경망이 이렇게 적은 변수를 가지는데는 두 가지 이유가 있습니다 그 중 하나가 변수 공유입니다              
변수 공유가 발견된 계기는 세로 윤곽선 검출기 같은 속성 검출기 관찰입니다              
이미지의 한 부분에 유용한 것이 다른 부분에도 유용한 것이죠              
만약 세로 윤곽선을 검출하기 위해 3 x 3 필터를 사용하게 된다면 동일한 3 x 3 필터를 여기도 사용할 수 있고              
다음 위치와 그 다음 위치에도 사용할 수 있습니다              
각각의 특성 검출기의 값은 입력 이미지의 여러 위치에서  동일하게 사용할 수 있습니다              
세로 윤곽선이나 다른 특성들을 검출할 때 말이죠              
윤곽선 같은 하급 속성에도 적용되고 눈이나 고양이 같은 것을 인식하는 상급 특성에도 적용이 됩니다              
9 개의 변수를 공유하며 16 개의 출력을 계산하는 것은 변수의 개수를 줄이는 방법 중 하나입니다              
그리고 세로 윤곽선 검출기 같은 속성 검출기에서는               
왼쪽 위의 계산된 결과와 동일한 속성이 이미지의 오른쪽 아래에도 유용하게 사용될 수 있습니다              
그래서 두 부분이 별개의 속성 검출기를 학습할 필요가 없죠              
어쩌면 왼쪽 위와 오른쪽 아래가 서로 다른 데이터 세트를 가져서 서로 다르게 보일 수 있지만              
충분히 비슷해서 속성 검출기를 공유해도 문제가 없게 됩니다              

# 희소 연결
![image](https://user-images.githubusercontent.com/50114210/71471300-68250380-2812-11ea-98ac-f2076f143bfb.png)                         
두 번째로 합성곱 신경망이 상대적으로 적은 변수를 가지는 이유는 희소 연결입니다                
여기 0 은 3 x 3 합성곱으로 계산된 것입니다 그래서 입력의 3 x 3 영역에만 영향을 받습니다                
그래서 이 출력값은 36 개의 입력 중 이 9 개와만 연결되어 있죠                
나머지 픽셀 값들은 이 결과값에 아무런 영향을 주지 않습니다 이것이 희소 연결의 의미입니다                
또 다른 예를 들면 이 결과값은 이 9 개의 입력에만 영향을 받습니다                
그래서 이 9 개의 입력 속성이이 결과값과 연결되어지고                 
다른 픽셀들은 이 결과값에 아무런 영향을 주지 않습니다                

# 이동 불변성
그래서 이 두가지 방법으로 신경망의 변수가 줄어들어서                 
작은 훈련 세트를 가지게 하고 과대적합 또한 방지할 수 있습니다                
합성곱 신경망은 이동 불변성을 포착하는데 용이하기도 합니다                
이 관찰은 고양이 사진에서 사진이 몇 픽셀 이동해서 여전히 분명한 고양이인 것과 같죠                
합성곱 구조는 신경망과 해당 코드에 도움을 줍니다                
몇 픽셀 이동한 이미지도 유사한 속성을 가지게 되고 동일한 결과를 얻게 되죠                
모든 이미지의 위치에 동일한 필터를 적용하고 초반과 이후의 층들에도 그렇기 때문에                 
신경망에서 자동으로 학습할 수 있고 이동 불변성을 포착할 수 있습니다                
이것이 합성곱 신경망이 컴퓨터 비전 분야에서 효과적인 이유입니다                

# 컨벌루션 신경망 학습
![image](https://user-images.githubusercontent.com/50114210/71471320-7a06a680-2812-11ea-82f5-7336f3d0d663.png)                                
이제 이것을 전부 조합해서 하나의 신경망을 훈련시켜 봅시다                    
고양이 인식기를 구축하려 하기 위해 훈련 세트를 구성하려 할 때                    
x 는 이미지이고 y 는 이진 레이블 혹은 k 개의 클래스 중 하나이며                    
합성곱 신경망 구조를 사용하기로 했다고 합시다 이미지에서부터 시작해서 합성곱과 풀링 층을 가지고                    
또 완전 연결 층 뒤에는 소프트맥스 출력값인 y 의 예측값입니다                    
합성곱 신경망과 완전 연결 층은 w 라는 변수를 가지게 되고                    
편향 b 를 가지는데 변수의 설정으로 비용 함수를 찾을 수 있게 됩니다                    
이전에 봤던 것과 유사하게 말이죠 무작위로 w 와 b 를 초기화함으로써 비용 J 를 계산할 수 있습니다                    
신경망의 훈련 세트에 대한 예측의 손실의 합을 m 으로 나눈 것이죠                    
그래서 이 신경망을 훈련시키기 위해서는 경사 하강이나 모멘텀 경사 하강이나                    
RMSprop 이나 다른 알고리즘을 사용해서 변수를 최적화할 수 있습니다                    
비용 함수 J 를 줄이기 위해서 말이죠                    
그리고 이것이 가능하다면 굉장히 효율적인 고양이 인식기나 다른 검출기를 만들 수 있습니다                    

# 아웃트로
이제 합성곱 신경망의 모든 기본 구성 요소들을 살펴보았고                    
어떻게 그것을 효과적인 이미지 인식 시스템이 넣을지 살펴보았습니다                    
이어서 합성곱 신경망을 더 깊이 있게 살펴볼 것입니다                    
전에 합성곱 신경망에는 많은 하이퍼파라미터가 있다고 했었죠                    
그래서 다음 주에는 가장 효과적인 합성곱 신경망의 구체적인 예를 보고                    
어떤 신경망의 구조가 효과적인지 그 패턴을 알아볼 수 있게 되고                    
또 많은 사람들이 주로 하는 것은 다른 사람들이 논문으로 발표한 구조를 활용하는 것입니다                     
다음 주에 구체적인 예를 보면서 그 방법을 익힐 수 있을 것이고                    
그걸 넘어서 더 좋은 합성곱 신경망에 대한 영감을 얻을 수 있습니다                    
