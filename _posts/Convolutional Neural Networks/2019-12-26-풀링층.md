---
layout: post
title: "풀링층"
tags: [convolutional neural network, pooling layer, max pooling, average pooling]
categories: [Convolutional Neural Networks]
---

# 학습 목표
- 풀링 층을 알아본다.

# 핵심 키워드
- 합성곱 신경망
- 풀링 층
- 최대 풀링
- 평균 풀링

# 학습 내용
- 합성곱 신경망에서는 풀링 층을 사용해 표현의 크기를 줄임으로써 계산속도를 줄이고 특징을 더 잘 검출해낼 수 있습니다.
- 최대 풀링과 평균 풀링, 두 가지 종류가 있습니다. 보통 최대 풀링을 사용합니다.
![image](https://user-images.githubusercontent.com/50114210/71459451-deae0b00-27ea-11ea-9b38-d821d7186ab7.png)       
- 최대 연산의 역할을 이미지의 특징이 필터의 한 부분에서 검출되면 높으 점수를 남기고 그렇지 않으면 다른 최대값들에 비해 상대적으로 작아져, 특징을 더 잘 남긴다는 것입니다.
- 위 예시의 최대 풀링은 필터 크기가 2, 스트라이드가 2, 패딩이 없는 필터를 합성곱 연산이 아닌 최대 연산을 하는 것과 같습니다. 즉, 이전 강의에서 이야기한 공식이 풀링 층에서도 적용이 됩니다. 즉, 4 * 4 이미지의 출력 결과는 2 * 2가 됩니다.

# 인트로
합성곱 층 외에도 합성곱 신경망은 풀링 층을 사용하여             
표현 크기를 줄임으로써 계산 속도를 높이고 특성을 훨씬 더 잘 검출해낼 수 있습니다             
먼저 풀링의 예를 보고 그 이유를 살펴봅시다             

# 맥스 풀링이란
![image](https://user-images.githubusercontent.com/50114210/71460000-5c731600-27ed-11ea-8501-c8718b403f61.png)          
4 x 4 크기의 입력이 있고 최대 풀링이라는 풀링을 적용한다고 할 때             
최대 풀링을 구현한다면 2 x 2 의 출력이 나올 것입니다             
그 방법은 꽤나 간단한데 4 x 4 의 입력을 여러 구간으로 나누면 됩니다             
네 구간을 다음과 같이 색칠하고 2 x 2 의 출력에서 각각의 출력은 해당 색의 구간에서 최대값이 됩니다             
왼쪽 위 구간에서 4 개 중 최대값은 9 이고              
오른쪽 위 파란 부분의 최대값은 2 이고 왼쪽 아래는 6 이고 오른쪽 아래 최대값은 3 이죠             
각각의 숫자를 구하기 위해서는 2 x 2 영역의 최대값을 취합니다             
그래서 마치 f = 2 짜리의 필터를 적용하는 것과 같죠             
2 x 2 영역과 2 만큼의 스트라이드인 셈입니다             
그래서 이것이 최대 풀링의 하이퍼파라미터입니다             
왜냐하면 필터 크기인 2 x 2 만큼의 영역에서 9 를 얻고             
두 칸을 이동한 다음 영역에서 2 를 얻을 수 있고              
행을 두 칸 내려가면 6을 얻고 또 오른쪽으로 두 칸 이동하면 3 을 얻습니다             
이 사각형이 2 x 2 이기 때문에 f 는 2 가 되고 스트라이드가 2 이기 때문에 s 는 2 입니다             

# 맥스 풀링의 직관
최대 풀링이 하는 작업을 한 번 생각해보면 이 4 x 4 입력을 어떤 특성의 집합이라 할 때             
아닐 수도 있지만 이 4 x 4 영역을 어떤 특성이나 어떤 신경망 층의 활성값이라고 할 때             
가장 큰 수가 특정 특성을 의미할 수도 있습니다             
왼쪽 위 사분면에서 어쩌면 세로 윤곽선이나 눈일 수도 있고              
하지만 분명히 왼쪽 위 사분면에 어떤 특성이 존재합니다 고양이의 눈을 감지하는 특성일 수 있죠             
그리고 오른쪽 위 사분면에는 이 특성이 존재하지 않을 수도 있죠             
그래서 이 최대 연산은 이러한 특성이 한 곳에서 발견되면 그것을 최대 풀링의 결과로 내는 것입니다             
그래서 최대 연산이 하는 일은 한 특성이 필터의 한 부분에서 검출되면 높은 수를 남기고             
만약 특성이 검출되지 않고 오른쪽 위 사분면에 존재하지 않으면 그 안의 최대값은 여전히 작은 수로 남게 됩니다             
최대 풀링을 직관적으로 본 것이죠             

# 풀링이 잘 되는 이유는 불분명하다             
하지만 사람들이 최대 풀링을 사용하는 주된 이유는             
많은 실험 속에서 성능이 좋고 방금 말한 직관은 종종 드는 이유지만             
아무도 그 이유를 완전히 알지는 못합니다             
합성곱 신경망에서 최대 풀링이 잘 작동하는 이유 말이죠             

# 학습이 불가능한 변수
최대 풀링의 한 가지 흥미로운 점은 여러 하이퍼파라미터가 있지만              
학습할 수 있는 변수가 없다는 것입니다 경사 하강으로 학습할 수가 없죠             
f 와 s 가 고정된 값이라서 경사 하강이 바꿀 수 없습니다             

# 맥스풀링 예시 2
![image](https://user-images.githubusercontent.com/50114210/71460014-6d238c00-27ed-11ea-90be-22f39f287200.png)      
이번에는 또 다른 하이퍼파라미터의 예시를 한 번 살펴봅시다             
여기 5 x 5 의 입력이 있고 적용할 최대 풀링의 필터 크기는 여기 5 x 5 의 입력이 있고             
적용할 최대 풀링의 필터 크기는 3 x 3 이라서 f 는 3 이고 1 의 스트라이드를 사용해봅시다             
그러면 출력의 크기는 3 x 3 이 되겠죠             
이전 시간에 합성곱 층에서 출력을 계산하는 공식이 여기서도 성립합니다             
최대 풀링에서도 말이죠 그래서 n + 2p - f / s + 1 최대 풀링에서도 말이죠             
그래서 n + 2p - f / s + 1 이것으로 최대 풀링의 출력 크기를 계산할 수 있습니다             
하지만 이 예시에서는 3 x 3 출력의 각 요소들을 한 번 계산해봅시다             
왼쪽 위의 요소는 이 부분을 살펴볼 것입니다             
필터의 크기가 3 이기 때문에 3 x 3 의 영역이고 최대값을 취합니다             
그러면 9 를 얻고 스트라이드가 1 이기 때문에 한 칸 이동합니다             
그리고 파란 상자의 최대값은 9 가 되고 한 칸 더 이동하면 파란 상자의 최대값은 5 가 됩니다             
그리고 다음 행으로 이동하는데 스트라이드가 1 이기 때문에             
한 칸 아래로 이동하고 이 영역의 최대값은 9 입니다             
이 영역의 최대값은 9 이고 이 영역에서 최대값은 5 입니다             
그리고 이 영역의 최대값은 8 이 되고 여기서 최대는 6 이고 오른쪽 아래는 9 가 됩니다             
그래서 f = 3, s = 1 인 하이퍼 파라미터로 이런 출력이 나오게 됩니다             
여기까지는 2차원 입력에 대한 최대 풀링이었고             

# 3차원 풀링
![image](https://user-images.githubusercontent.com/50114210/71460032-7e6c9880-27ed-11ea-80dd-0d37f084ba25.png)     
3차원 입력이라면 출력도 같은 크기를 가집니다 만약 5 x 5 x 2 라면 출력은 3 x 3 x 2 가 되겠죠              
그리고 최대 풀링을 계산하는 법은 방금 했던 계산을 그대로 각 채널에 적용하는 것입니다              
여기에 보이는 첫 번째 채널은 이렇게 위쪽에 그대로 남아있고              
두 번째 채널은 그 아래에 그려지고 똑같은 계산 과정을 거치면 두 번째 부분을 알 수 있습니다              
그리고 좀 더 일반화하면 5 x 5 x 채널의 수 라면              
출력은 3 x 3 x 같은 수의 채널 이 될 것입니다              
그리고 최대 풀링은 각 채널에 개별적으로 적용되겠죠 이것이 바로 최대 풀링입니다              

# 평균 불링
![image](https://user-images.githubusercontent.com/50114210/71460047-8e847800-27ed-11ea-9ea6-8073fa1b4599.png)       
또 자주 사용되지 않는 풀링의 종류가 있는데 바로 평균 풀링입니다              
예상하는 그대로일텐데 최대값을 취하는 대신 각 필터의 평균을 취합니다              
이 예시에서는 보라색 부분의 평균값은 3.75 이고 여기는 1.25 이고 4 그리고 2 입니다              
이게 f = 2, s = 2 의 하이퍼파라미터인 평균 풀링이고              
다른 하이퍼파라미터를 선택해도 됩니다              
요즘에는 최대 풀링이 평균 풀링보다 훨씬 더 많이 사용됩니다              
하나의 예외가 있는데 신경망의 아주 깊은 곳에서 평균 풀링을 사용해서              
7 x 7 x 1000 의 값을 단면적의 평균값을 취해서 1 x 1 x 1000 의 값을 취합니다              
하지만 신경망에서는 최대 풀링을 평균 풀링보다 훨씬 많이 사용됩니다              

# 풀링의 하이퍼파라미터
![image](https://user-images.githubusercontent.com/50114210/71460062-9fcd8480-27ed-11ea-87a6-fb8834b9e8c6.png)        
그래서 요약하자면 풀링의 하이퍼파라미터는 f 가 필터의 크기 s 가 스트라이드이고           
이 값들의 일반적인 선택은 f = 2, s = 2 인데 자주 사용되고           
높이와 너비를 절반 정도 만큼 줄어들게 하고           
하이퍼 파라미터의 일반적인 선택은 f = 2, s = 2 인데 높이와 너비를 절반으로 줄여주는 효과가 있습니다           
또 f = 3, s = 2 가 사용되는 것도 볼 수 있고           
그리고 또 다른 하이퍼 파라미터는 이진 비트로 최대 풀링인지 평균 풀링인지 알려주는 것이 있습니다           
원한다면 패딩에 해당하는 하이퍼 파라미터를 추가해도 됩니다만           
최대 풀링에서는 패딩을 거의 사용하지 않습니다           
그래서 p 의 일반적인 값은 0 이 되겠죠 패딩을 사용하지 않습니다           
그리고 최대 풀링의 입력으로 n_H x n_W x n_C 크기의 입력이 있으면 그 출력은 이렇게 됩니다           
n_W - f / s + 1 의 바닥값에 n_C 가 될 겁니다           
여기서 입력의 채널과 출력의 채널은 일치합니다 왜냐하면 풀링은 각 채널에 개별적으로 적용되기 때문이죠           
한 가지 유의할 점은 풀링에서는 학습하는 변수가 없습니다           
그래서 역전파를 적용해보면 역전파가 가능한 변수가 없습니다           
직접 혹은 교차 검증을 통해 정해진 하이퍼 파라미터이기 때문이죠           
그리고 그 이상은 없습니다 신경망이 한 층에서 계산하는 고정 함수이고 학습할 것이 없습니다           
그냥 고정 함수에 불과하죠 여기까지가 바로 풀링입니다          
