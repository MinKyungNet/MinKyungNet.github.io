---
layout: post
title: "Inception 네트워크의 아이디어"
tags: [Inception Network, bottlenect layer]
categories: [Convolutional Neural Networks]
---

# 학습 목표
- 인셉션 네트워크의 핵심개념을 알아본다.

# 핵심 키워드
- 인셉션 네트워크
- 병목 층

# 학습 내용
- 인셉션 네트워크 생각은 필터의 크기나 풀링을 결정하는 대신 전부다 적용해서 출력들을 합친뒤 네트워크로 하여금 스스로 변수나 필터 크기의 조합을 학습하게 만드는 것입니다.
![image](https://user-images.githubusercontent.com/50114210/71503168-6feab380-28b7-11ea-8bd5-f741af4dcfd9.png)        

- 위와 같은 인셉션 네트워크의 문제는 계산 비용입니다.
- 단순 5 * 5 필터만 봐도 필요한 곱셈은 28 * 28 * 32 * 5 * 5 * 192 = 약 1억 2000만개입니다.
- 하지만 이를 1 * 1 합성곱으로 해결할 수 있습니다.
![image](https://user-images.githubusercontent.com/50114210/71503279-e7b8de00-28b7-11ea-85c8-cacf300e3daa.png)          

- 5 * 5 합성곱을 사용하기 전에 1 * 1의 합성곱 연산을 통해 입력 이미지의 볼륨을 줄이는 작업을 합니다. 그 후에 다시 5 * 5 합성곱 연산을 하는데, 이때 계산 비용은 약 1240만개로 아래와 같습니다.
  - 1 * 1 합성곱 : 28 * 28 * 16 * 1 * 1 * 192 = 약 240만개
  - 5 * 5 합성곱 : 28 * 28 * 32 * 5 * 5 * 16 = 약 1000만개
- 학습에 필요한 계산 비용이 1/10 수준으로 크게 줄어든 것을 알 수 있습니다. 여기서 사용된 1 * 1 합성곱 층을 병목층이라고도 합니다.
- 병목층을 사용시 표현의 크기가 줄어들어 성능에 지장을 줄 지 걱정 될 수도 있는데, 적절하게 구현시 표현의 크기를 줄임과 동시에 성능에 큰 지장 없이 많은 수의 계산을 줄일 수 있습니다.

# 인트로
합성곱 신경망의 층을 디자인할 때 1 x 3 필터를 사용할지      
아니면 3 x 3, 5 x 5 혹은 풀링층을 원하는지 결정해야 합니다     
그래서 인셉션 네트워크가 하는 것은 이것을 전부 사용하는 것입니다     
네트워크가 복잡해지기는 하지만 성능은 뛰어납니다     

# 인셉션 개념
![image](https://user-images.githubusercontent.com/50114210/71503653-7c700b80-28b9-11ea-9b43-a0f0c51e4558.png)           
예시로 28 x 28 x 192 크기의 입력값이 있다고 해봅시다     
그래서 인셉션 네트워크는 필터의 크기를 정하지 않고     
합성곱 또는 풀링 층을 모두 사용하는 것입니다     

# 인셉션 구조
1 x 1 합성곱을 이용하면 28 x 28 x 64 의 크기를 가집니다         
그리고 만약 3 x 3 를 사용하게 된다면 28 x 28 x 128 이 될 것이고         
이 두 번째 볼륨을 첫 번째 볼륨 위에 쌓는 것입니다         
그리고 크기를 맞추기 위해 여기서 동일 합성곱을 사용해서 출력이 28 x 28 로 유지되게 해줍니다         
그래서 입력 크기인 28 x 28 과 같게 유지가 되는 것입니다         
어쩌면 5 x 5 필터가 나아 보여서 해보면 28 x 28 x 32 가 되죠         
역시 동일 합성곱을 사용해서 크기를 동일하게 유지해줍니다         
합성곱 층을 원하지 않는다면 풀링 층을 적용해봅시다         
또 다른 출력이 나올텐데 역시 같이 쌓아줍니다         
여기 풀링의 출력 크기는 28 x 28 x 32 가 되죠         
최대 풀링에서 크기를 맞추려면 패딩을 사용해야 합니다          
이것은 보기 드문 풀링 형태인데 만약 높이와 너비를 28 x 28 로 하고          
다른 출력들의 크기와 맞추려면 패딩과 1 의 스트라이드를 사용해야 합니다이          
세세한 것이 지금은 우스워 보일 수 있지만 일단은 넘어가고 이후에 모두 합쳐지도록 만들 것입니다         
이러한 인셉션 모듈에서는 특정한 크기를 입력하면 출력은 이 숫자를 전부 더한 크기입니다         
32 + 32 + 128 + 64 는 256 이죠 그래서 이 인셉션 모듈의 입력은         
28 x 28 x 192 이고 출력은 28 x 28 x 256 입니다 이것이 바로 인셉션 네트워크의 핵심이죠         
왼쪽 아래에 있는 논문의 저자들이 이러한 구조의 네트워크를 만들었죠         
그래서 기본적인 개념은 필터의 크기나 풀링을 결정하는 대신          
그것들을 전부 다 적용해서 출력들을 다 엮어낸 뒤         
네트워크가 스스로 원하는 변수나 필터 크기의 조합을 학습하게 되는 것이죠         
그리고 여기 인셉션에 문제가 조금 있는데 바로 계산 비용입니다         

# 인셉션의 큰 계산비용
![image](https://user-images.githubusercontent.com/50114210/71503673-99a4da00-28b9-11ea-9174-c754cd9674db.png)                    
이 5 x 5 필터로 만들어진 블록의 계산 비용을 알아봅시다         
이전 슬라이드의 5 x 5 필터 부분만 집중해서 보게 되면         
일단 입력으로는 28 x 28 x 192 의 블록이 있고         
5 x 5 동일 합성곱의 필터 32 개로 28 x 28 x 32 의 출력이 나오게 됩니다         
전 슬라이드에서는 이것을 얇은 보라색 조각으로 그렸었는데         
여기서는 좀 더 평범한 파란 블록으로 그렸습니다         
이제 이 28 x 28 x 32 출력의 계산 비용을 한 번 알아봅시다         
우선 32 개의 필터가 있습니다 출력값이 32 개의 채널이기 때문이죠         
그리고 각 필터는 5 x 5 x 192 입니다 그래서 출력 크기가         
28 x 28 x 32 라서 28 x 28 x 32 개의 숫자를 계산해야 합니다         
그리고 각각의 수에 이만큼의 곱셈을 해줘야 합니다         
그래서 총 필요한 곱셈의 수는 각각의 출력값을 계산하기 위한 곱셈의 수에다가         
출력값의 개수를 곱한 수가 되는 것이죠 이 모든 수를 곱하면 1억 2천만 정도가 됩니다         
현대의 컴퓨터에서 1억 2천만의 곱셈을 할 수는 있겠지만 여전히 비용이 큰 계산입니다         

# 해결법
![image](https://user-images.githubusercontent.com/50114210/71503683-ac1f1380-28b9-11ea-8c0b-e1d7a477b630.png)                       
다음 슬라이드에서는 1 x 1 합성곱을 사용해서 계산 비용을 줄일 수 있습니다         
1억 2천만의 10 분의 1 정도로 말이죠 그래서 이 1억 2천만이라는 숫자를 잘 기억해두고          
다음 슬라이드에서 보게 될 것과 비교해봅시다         
여기 또 다른 방식으로 28 x 28 x 192 의 입력으로           
28 x 28 x 32 를 출력하는 구조가 있는데 다음과 같습니다          
볼륨을 입력 받고 1 x 1 합성곱을 사용해서 192 개의 채널을 16 개로 줄이고          
이 볼륨에 5 x 5 합성곱을 해주면 최종 출력을 얻게 됩니다          
입력과 출력 크기는 전과 같죠 입력은 28 x 28 x 192 이고 출력은 28 x 28 x 32 입니다          
여기서 한 일은 왼쪽의 큰 볼륨을 가지고 여기 중간 크기의 볼륨으로 줄인 것입니다          
192 개 대신 16 개의 채널만 가지고 있죠 이것은 병목 층이라고도 불립니다          
일반적으로 병의 목은 어떤 것의 가장 작은 부분을 가리키기 때문에          
이렇게 생긴 유리병이 있다면 여기에 코르크가 있겠고 병의 목 부분이 병에서 가장 작은 부분입니다          
그래서 병목 층도 네트워크에서 가장 작은 부분을 나타냅니다          
크기를 다시 늘이기 전에 이미지를 줄이는 것이죠          

# 1 * 1 사용시 
이것의 계산 비용을 한 번 알아봅시다          
1 x 1 합성곱을 사용하기 위해서는 16 개의 1 x 1 x 192 의 필터가 필요합니다          
그래서 이 28 x 28 x 16 의 출력을 계산하기 위한 비용은           
이만큼의 출력값이 있고 각각 192 번의 곱셈이 필요합니다          
1 x 1 x 192 라고 쓰는게 맞겠죠 이것을 계산하면 240만 정도입니다          
그러면 두 번째 계산은 어떨까요 이것이 첫 번째 합성곱 층의 비용이었는데          
두 번째 합성곱 층의 비용은 우선 이만큼의 출력값이 있고 28 x 28 x 32 개에서          
각 출력값마다 5 x 5 x 16 의 필터를 적용해줘야 합니다          
이것을 계산하면 1천만 정도가 되죠 그래서 총 필요한 곱셈의 수는 240만과 1천만의 합입니다          
이전 슬라이드와 비교해보면 계산 비용을 1억 2천만 개의 곱셈에서           
10분의 1 정도인 1천 2백만 개의 곱셈으로 줄인 셈이 되는 것이죠          
그리고 필요한 덧셈의 수는 곱셈의 수와 비슷하기 때문에 곱셈의 수만 계산하는 것이죠          

# 정리
정리하자면 신경망의 층을 구축할 때 1 x 1, 3 x 3, 5 x 5 또는 풀링 층인지           
고민하기 원하지 않는다면 인셉션 모델은 그것들을 전부 다 실행해서 함께 엮는 것입니다          
그리고는 계산 비용 문제에 대해서는 1 x 1 합성곱을 이용해서          
병목 층을 만들어서 계산 비용을 상당히 많이 줄일 수 있었습니다          
그래서 표현 크기를 줄이는 것이 성능에 지장을 줄지 걱정될 수 있는데          
만약 이 병목 층을 적절하게 구현할 수 있다면          
표현 크기를 줄이는 동시에 성능에 큰 지장 없이 많은 수의 계산을 줄일 수 있습니다          
이것이 인셉션 모듈의 핵심 개념이었습니다          
