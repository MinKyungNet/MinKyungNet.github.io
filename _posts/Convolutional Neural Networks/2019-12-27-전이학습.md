---
layout: post
title: "전이학습"
tags: [transfer learning, freeze]
categories: [Convolutional Neural Networks]
---

# 학습 목표
- 전이 학습을 어떻게 이용하는지 배운다.

# 핵심 키워드
- 전이 학습
- 동결

# 학습 내용
- 컴퓨터 비전 프로그램을 구성할 때 무작위한 초기화 과정으로 시작하는 대신 다른 이들이 훈련시켜놓은 구조를 다운 받는 것이 훨씬 효과적입니다.
- 미리 훈련된 모델로 풀고자하는 무제의 초기값으로 사용할 수 있습니다. 즉, 전이 학습을 통해 공유되는 지식을 전달하는 것입니다.
- 오픈 소스에서 모델과, 모델에 적용된 가중치를 함께 받아야합니다.
- 풀고자하는 문제의 가지고 있는 데이터가 적을 경우, 최종 분류층인 소프트맥스 층을 제거하고 문제에 알맞게 분류층을 설정합니다. 그리고 모델의 나머지 부분은 학습되지 않게 동결시키고 최종층만 훈련시킵니다.
- 데이터가 많을 수록 동결층의 개수는 줄어들고 훈련시킬 층의 개수는 늘어납니다.

# 인트로
컴퓨터 비전 프로그램을 구성할 때 무작위한 초기화 과정으로 시작하는 대신          
다른 이들이 훈련시켜놓은 구조를 다운 받는 것이 훨씬 효과적입니다          
그것을 이용해서 새로운 관심있는 작업에 전달하는 것이죠          
컴퓨터 비전 커뮤니티는 인터넷 상에 많은 데이터 세트를 공개하고 있습니다          
ImageNet 이나 MS-COCO 나 Pascal 등 사람들이 온라인 상에 올려놓은 여러 데이터 세트들이 있습니다          
많은 컴퓨터 비전 연구자가 훈련시켜놓은 데이터 말이죠          
때로는 이 훈련이 몇 주 걸리거나 수많은 GPU 를 필요로 합니다          
그래서 다른 누군가가 이미 귀찮게 고성능의 연구를 거쳤기 때문에          
누군가가 오랜 기간 걸쳐 얻은 오픈 소스를 이용하면 신경망의 좋은 초기화 자료로 사용될 수 있습니다          
전이 학습을 이용해서 공유된 데이터 세트를 통해 얻을 지식을 우리의 문제에 전달하는 것이죠          
이것에 대해 좀 더 깊이 살펴봅시다          

# 코드와 가중치를 받아오자
![image](https://user-images.githubusercontent.com/50114210/71515052-b60a3c00-28e4-11ea-85e9-80939abda68e.png)                        
먼저 한 예시를 보겠습니다 만약 고양기 인식기를 만들어서          
자신의 애완묘를 인식하려 한다면 인터넷에 따르면
Tigger 는 흔한 고양이 이름 중에 하나이고 Misty 역시 흔한 고양이의 이름입니다
그래서 자신의 고양이 Tigger 와 Misty 라고 한다면 둘 다 아닌 경우도 있겠죠          
그래서 세 개의 클래스를 가진 분류하는 문제가 되었습니다          
사진이 Tigger 인지 Misty 인지 혹은 둘 다 아닌지 말이죠 두 고양이가 모두 나오는 경우는 제외합시다          
아마 Tigger 와 Misty 에 대한 사진이 많지는 않아 훈련 세트는 작을겁니다          
그래서 온라인 상에서 신경망의 오픈 소스 구현법을 다운 받는데          
코드만 받는 것이 아니라 가중치도 함께 받아야 합니다          

# 원하는 작업에 맞게 변형하자
많은 네트워크가 ImageNet 같은 데이터 세트를 기반으로 훈련한 것인데          
수천 개의 클래스가 존재해서 소프트맥스 유닛은 그 중 하나를 출력합니다          
그래서 이 소프트맥스 층을 없애서 직접 소프트맥스 유닛을 만드는 것이죠           
Tigger 나 Misty 나 둘 다 아니라고 출력하도록 말이죠           
네트워크의 관점에서 이 모든 층을 고정되어있다고 여기면 모든 층의 변수들이 고정되어 있고           
소프트맥스 층과 관련된 변수만 훈련시키는 것이죠           
Tigger, Misty, 혹은 둘 다 아닌 3 개의 가능성만 있는 소프트맥스 층 말입니다           

# 가중치를 고정시키자
누군가가 이미 훈련시킨 가중치를 사용함으로써 작은 데이터 세트로도 좋은 성능을 낼 수 있습니다           
그리고 많은 딥러닝 프레임워크는 이러한 작업을 지원하기 때문에           
프레임워크에 따라서 훈련가능변수 = 0 으로 설정을 하게 되면 이부분을 훈련시키지 않게 되고           
또는 freeze = 1 으로 설정해줄 수도 있습니다           
이것이 딥러닝 프레임워크가 훈련 여부를 결정하는 방법이고            
이 경우에는 소프트맥스 층의 가중치만 훈련해야 합니다 이전 층의 가중치는 동결시켜야 하죠           

# 데이터가 적은 경우
또 다른 유용한 방법 중 하나는 이전 층들이 동결되어 있기 때문에           
훈련시키지 않기 때문에 하나의 고정 함수가 발생해서 이미지 X 를 특정 활성값으로 전달합니다           
그래서 훈련의 속도를 높이는 방법은 이 층을 미리 계산하는 것이죠           
활성값의 특성을 디스크에 미리 저장해놓으면 됩니다           
이 고정 함수를 가지고 어떤 이미지 X 를 입력 받아서            
특성 벡터를 계산하고 그것으로 소프트맥스 모델을 훈련합니다           
그래서 그 계산을 도울 수 있는 과정이 활성값을 미리 계산하는 것이죠           
모든 훈련 세트의 활성값을 저장하면 소프트맥스만 훈련하면 됩니다           
미리 계산해놓고 그것을 디스크에 저장하는 방식은            
매번 그 활성값을 계산하지 않아도 된다는 장점이 있습니다 그 훈련 세트를 거치게 될 때 말이죠           
작업에 필요한 훈련 세트가 작을 때 이런 식으로 하면 됩니다           

# 데이터가 많은 경우
![image](https://user-images.githubusercontent.com/50114210/71515069-c5898500-28e4-11ea-88c3-df135b3f4e3c.png)                   
만약 더 큰 데이터 세트가 있어서 굉장히 많은 Tigger 와 Misty 와 둘 다 없는 사진들이 있다면           
몇 개의 층만 동결시키고 이후의 층들은 훈련을 시켜줍니다           
출력 층의 클래스는 다르기 때문에 마찬가지로 바꿔줘야 합니다            
Tigger 와 Misty 와 둘 다 아닌 것으로 말이죠 여러 가지 방법이 있는데 마지막 몇 개의 층을 선택해서           
초기화로 활용한 뒤 경사하강법을 사용해줘도 되고 또는 뒤 쪽의 층들을 버리고           
새로운 은닉층을 만들고 소프트맥스 출력을 해줘도 됩니다 두 방법 모두 해볼만하죠           
데이터가 많을수록 동결시키는 층의 개수는 줄어들고 훈련시킬 층의 개수는 늘어나게 됩니다           
만약 더 큰 데이터 세트로 충분한 데이터가 있다면 하나의 소프트맥스 유닛만 훈련하는 것이 아니라            
마지막 몇 개의 층을 조합한 작은 신경망을 훈련할 수 있습니다           

# 데이터가 아주 많은 경우
![image](https://user-images.githubusercontent.com/50114210/71515077-d4703780-28e4-11ea-8b01-62990ad0302f.png)                  
마지막으로 아주 많은 데이터가 있다면 오픈 소스 네트워크와 가중치           
전부를 가지고 초기화 과정으로 사용하고 네트워크 전체를 다시 훈련시킵니다           
천 개의 노드를 가진 소프트맥스라면 3 개 짜리로 바꿔주긴 해야겠죠           
우리가 필요로 하는 출력으로 말입니다           
더 많은 데이터 즉 이 경우에는 더 많은 사진이 있을 수록 더 많은 층을 훈련시킬 수 있고           
극단적인 경우에는 다운 받은 가중치 전부를 초기값으로 사용해서           
무작위 초기화를 대체한 뒤 경사하강법을 사용할 수 있습니다           
네트워크의 모든 층을 훈련시키고 업데이트 하면서 말이죠           

# 아웃트로
이것이 합성곱 신경망 훈련의 전이 학습이었습니다           
실제로는 인터넷에서 받은 오픈 소스 데이터 세트는 굉장히 크고           
누군가가 몇 주에 걸쳐 훈련시킨 것이기 때문에           
많은 컴퓨터 비전 응용프로그램에서 오픈 소스 가중치를 초기값으로 사용하면 굉장히 유용합니다           
그래서 딥러닝의 모든 응용 분야에서 컴퓨터 비전은 전이 학습을 해야만 하는 분야입니다           
이례적으로 큰 데이터 세트를 가지고 있지 않다면 말이죠           
전이 학습은 매우 가치있습니다 말도 안되게 큰 데이터 세트나 예산을 가지고 있지 않다면 말이죠           
