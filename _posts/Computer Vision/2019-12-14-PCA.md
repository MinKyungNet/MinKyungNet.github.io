---
layout: post
title: "PCA"
tags: [pca, eigen, scikit-learn, component]
categories: [Computer Vision]
---

# 1. 주성분 분석(Principal Component Analysis, PCA)  

- 대표적인 차원 축소(dimensionality reduction) 알고리즘  
- 정보 손실을 최소화하면서 데이터의 차원을 더 작은 차원으로 줄이는 것을 목적으로 함

<pr>

## 1) 투영과 분산
- 데이터를 잘 표현하는 축을 찾는다는 것?
- 분산이 크도록하는 축을 찾는것

![image](https://user-images.githubusercontent.com/50114210/70845395-85acb180-1e91-11ea-8721-e7bcc8330bdb.png)
  
- 원래 공간에 퍼져 있는 정도가 변환된 공간에서도 얼마나 잘 유지가 되는지를 평가 척도로 사용 -> **분산**으로 측정  
- 단계  
  - ① 데이터에 대해서 분산이 가장 큰 축을 찾고 그 축으로 투영된 데이터의 분산을 계산  / 측정 척도는 분산으로 한다. 분산이 작으면 좋지 않은 축을 선택한 것이다.
  - ② 첫 번째 축에 직교하면서 두 번째로 분산이 큰 축을 찾음 / @ 차원이 높아지면 직교는 어케 이뤄지는거임
  - ③ 데이터 차원 수만큼의 축을 찾을 때까지 ①~② 과정을 반복  
- i번째 축(단위 벡터)을 i번째 주성분(principal component)이라고 함  

<pr>

![image](https://user-images.githubusercontent.com/50114210/70845398-8e9d8300-1e91-11ea-8c0c-67c21d898fae.png)

## 2) 계산 및 적용
- ※ 고유값(eigenvalue)과 고유벡터(eigenvector)   
  - 임의의 정방행렬 A(선형변환 함수)에 대해 다음 식을 만족하는 0이 아닌 벡터 $\bf{x}$를 **고유벡터**, 상수 $\lambda$를 **고유값**이라고 정의
$$
A\bf{x}=\lambda \bf{x}
$$
  - 기하학적 의미  
    - 수많은 벡터 중 어떤 벡터 $\bf{x}$는 $A$에 의해 변환된 결과 $A\bf{x}$와 크기만 $\lambda$만큼 다르고 방향은 같은 벡터임 => 이러한 벡터 $\bf{x}$를 고유벡터라고 함  
    - 참고: https://twlab.tistory.com/46
  
<br>  

- $\bf{\Sigma}$를 공분산 행렬이라고 할 때, PCA를 풀어서 나온 식에서 $\bf{u}$는 고유벡터, $\lambda$는 고유값에 해당함  
$$
\bf{\Sigma} \bf{u} = \lambda \bf{u}
\tag{1}
$$

<br>  

- 즉, 공분산 행렬 $\bf{\Sigma}$를 구한 다음 $\bf{\Sigma}$의 고유벡터 $\bf{u}$를 찾으면 데이터의 분산을 잘 표현하는 주성분을 찾을 수 있음  
- 분산 $\lambda$을 기준으로 내림차순 정렬을 한 후, 상위 d개 만큼의 주성분만 선정하여 데이터의 차원을 D -> d차원(d < D)으로 줄임  

$$
U = \begin{bmatrix}
\bf{u}_1 \\
\bf{u}_2 \\
\vdots \\
\bf{u}_d
\end{bmatrix}
$$
- 입력 벡터 $\bf{x}$를 선정된 주성분 행렬 $U$를 사용하여 출력 벡터 $\bf{y}$로 변환  
$$
\bf{y} = U \bf{x}
\tag{2}
$$

<br>

- 선정한 주성분만 사용하여 원래 벡터 $\bf{x}$로 복원  
$$
\bf{x} = U^{-1}\bf{y}
\tag{3}
$$


#### [Reference]
- [link #1] https://excelsior-cjh.tistory.com/167  
- [link #2] https://sandipanweb.wordpress.com/2018/01/06/eigenfaces-and-a-simple-face-detector-with-pca-svd-in-python/  
- [link #3] https://www.learnopencv.com/eigenface-using-opencv-c-python/  

# 2. Practice  
- 얼굴 데이터셋   
 LFW(Labeled Faces in the Wild): http://mlsp.cs.cmu.edu/courses/fall2013/assignments/assignment2/lfw1000.zip  
<br> 
- PCA 라이브러리 설치  
  - pip install scikit-learn

## 1) 데이터 확인하기

```python
import cv2
import numpy as np
import glob
import matplotlib.pyplot as plt
%matplotlib inline

## 파일 리스트 읽어오기
listOfFiles = glob.glob('lfw1000/*.pgm') # 지정한 경로 내 확장자가 .pgm인 파일을 모두 읽어서 리스트로 반환 정규 표현식
nData = len(listOfFiles)
print('# of files = {}'.format(nData))

## 이미지 배열로 저장하기
faces = []
for file in listOfFiles:
    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)
    faces.append(img)
    
faces = np.array(faces) # list -> array

## 데이터셋 정보 확인하기
print(type(faces))
print(faces.dtype)
print(faces.shape)

>>>

# of files = 1071
<class 'numpy.ndarray'>
uint8
(1071, 64, 64)
```

```python
## 데이터 샘플 확인해보기
plt.figure(figsize=(13, 6))
plt.suptitle('sample images', fontsize=20)
for i in range(10):
    plt.subplot(2,5,i+1)
    plt.imshow(faces[i], cmap='gray')
    plt.axis('off')
    
plt.tight_layout()
plt.subplots_adjust(top=0.96)
plt.show()
```
![image](https://user-images.githubusercontent.com/50114210/70845364-07e8a600-1e91-11ea-8e56-d2895da4e9c5.png)

## 3) Scikit-Learn을 이용한 PCA 적용하기
- 각 요소들의 행렬 크기  
  - 단일 데이터 (64x64): 4096  
  - 학습 데이터셋: 1071×4096  
  - 공분산행렬: 4096×4096
  - 고유값: k (상위 k개 주성분)
  - 고유벡터: k×4096  
  
얼굴 이미지 하나가 64 * 64 차원이니까 얼굴 하나를 표현하기에 pca를 통해서 아주 섬세한 부분을 보는 것이 아니고 차원을 좀 줄여서 얼굴 이미지들을 표현해보자

```python
from sklearn.decomposition import PCA

## 2차원 -> 1차원 벡터 형태로 변환
print("Before reshape = {}".format(faces.shape))
# 1071개의 데이터가 들어가 있음
# -1차원을 줘서 앞의 차원이 1071이 되도록만 결정
faces = faces.reshape((nData, -1))
print("After reshape = {}".format(faces.shape))

print()

## PCA적용 (정수형 파라미터 입력 -> 사용할 주성분 개수를 지정)
pca = PCA(n_components=10)
# PCA를 임포트하고, 4096차원인데 몇 차원으로 사용하고 싶다고 결정하는 부분
# 4096차원을 10차원으로 표현하겠다는 뜻

pca.fit(faces) # 수식(1)에 해당
# 객체를 생성한 다음 어떤 데이터에 대해서 pca를 적용할 건지 fitting
# 분산이 큰 순서대로 정렬해서 던져준다
# 우리는 10차원의 데이터를 얻기 원했으니까
# 10개로 반환

eigenVectors = pca.transform(faces) # 수식(2)에 해당
# eigenVectors = pca.fit+_transform(faces) # 수식 (1) & (2)에 해당

print("shape of eigenVectors = {}".format(eigenVectors.shape))
print("shape of components = {}".format(pca.components_.shape))

# 10개의 축만 선택했는데 상위 10개의 축이 원래 데이터의 분산의 몇 프로를 표현하고 있는지 
print("explained_variance_ratio = {}".format(pca.explained_variance_ratio_))

>>>

Before reshape = (1071, 64, 64)
After reshape = (1071, 4096)

shape of eigenVectors = (1071, 10)
shape of components = (10, 4096)
explained_variance_ratio = [0.29378922 0.12629319 0.06304694 0.04017165 0.03541217 0.02161253
 0.01987717 0.01758739 0.01693448 0.01495814]
```

```python
## 평균 얼굴 벡터 시각화해보기
plt.imshow(pca.mean_.reshape((64,64)), cmap='gray')
# 1071장을 평균내서 1차원으로 변환해줬었기 때문에 reshape을 해주고 뿌려보면,
# 1071장의 얼굴 이미지가 대략 이렇게 생겼다.
plt.axis('off')
plt.title('avearge face')

plt.show()
```
![image](https://user-images.githubusercontent.com/50114210/70845369-1b940c80-1e91-11ea-957f-da93f7e0bfa8.png)

```python
## PCA 적용(0~1 실수형 파라미터 입력 > 데이터에서 표현하고자 하는 분산의 양을 지정)
pca = PCA(n_components=0.85)
eigenVectors = pca.fit_transform(faces)
# 0에서 1사이의 실수 값을 넣어주면 
# 원래 데이터의 몇 퍼센트의 데이터를 유지하면서 차원을 축소하고 싶은지
# 85의 데이터를 유지하면서 차원 축소를 하고 싶어
# 사람은 모르지만 분산의 양을 조절해줌

print("n_components = {}".format(pca.n_components_))
print("explained_variance_ratio = {}".format(pca.explained_variance_ratio_))
print(sum(pca.explained_variance_ratio_))
# 상위 48개의 벡터들로 이미지를 표현하면 원래 데이터의 85를 표현가능하다.

>>>

n_components = 48
explained_variance_ratio = [0.29378922 0.12629319 0.06304694 0.04017165 0.03541217 0.02161253
 0.01987717 0.01758744 0.01693449 0.01495816 0.0132944  0.01280355
 0.01112295 0.0092924  0.00858141 0.00794731 0.00766109 0.00759214
 0.00704212 0.00646335 0.00621586 0.00597905 0.00572021 0.00535124
 0.00513402 0.00505057 0.00479954 0.00462193 0.004467   0.00438083
 0.00432892 0.00414855 0.00391991 0.00371639 0.00365352 0.00352683
 0.00335685 0.00329078 0.00315162 0.00299622 0.0029649  0.00293174
 0.00278404 0.00273643 0.00256466 0.00254946 0.0024336  0.00239381]
0.8506521565968779
```

## 4) PCA 결과 확인하기
### a. i번째 component 확인하기

```python
from sklearn.decomposition import PCA

## 2차원 -> 1차원 벡터 형태로 변환
faces = faces.reshape((nData, -1))

## PCA적용
pca = PCA(n_components=400)
eigenVectors = pca.fit_transform(faces)

## top~100 eigenface 시각화
plt.figure(figsize=(17,17))
plt.suptitle('top-100 eigenfaces', fontsize=20)
for i in range(100):
    plt.subplot(10, 10, i+1)
    plt.imshow(pca.components_[i].reshape((64, 64)), cmap='gray')
    plt.axis('off')
    
plt.subplots_adjust(top=0.96)
plt.show()

## top~400 eigenface 시각화
plt.figure(figsize=(17,17))
plt.suptitle('top-400 eigenfaces', fontsize=20)
for i in range(400):
    plt.subplot(20, 20, i+1)
    plt.imshow(pca.components_[i].reshape((64, 64)), cmap='gray')
    plt.axis('off')

plt.subplots_adjust(top=0.96, wspace=0.05, hspace=0.05)
plt.show()
```

![image](https://user-images.githubusercontent.com/50114210/70845373-2fd80980-1e91-11ea-8c17-6d081e4c05c6.png)

![image](https://user-images.githubusercontent.com/50114210/70845376-36668100-1e91-11ea-91c3-ee739546adb0.png)

### b. 시각화를 통한 component의 의미 유추하기
```python
meanFace = pca.mean_.reshape((64,64))
components = []
for k in range(5):
    components.append(pca.components_[k].reshape((64,64)))

import matplotlib.pyplot as plt
%matplotlib inline

# k = 0 # 몇 번째 성분을 사용할 것인지

for k in range(5):
    plt.figure(figsize=(17,5))
    plt.subplot(2, 7, 4)
    plt.imshow(components[k], cmap='gray')
    plt.axis('off')
    
    for i in range(7):
        plt.subplot(2, 7, 8+i)
        w = (i - 3) * 500 # component의 가중치
        plt.imshow(meanFace + w * components[k], cmap='gray')
        plt.axis('off')
        
    plt.suptitle("mean face with component {} added".format(k),fontsize=15)
    plt.tight_layout()
    plt.subplots_adjust(top=0.90, wspace=0.05, hspace=0.05)
    plt.show()

# 밝은 곳이 가중치가 높은거임
# 축, 성분, 차원, 컴포넌트가 여기서는 다 동일한 말이다.
```
![image](https://user-images.githubusercontent.com/50114210/70845385-66ae1f80-1e91-11ea-83b6-b249698e9bb4.png)

![image](https://user-images.githubusercontent.com/50114210/70845388-7168b480-1e91-11ea-8c11-b1ea6b5fe5c8.png)

![image](https://user-images.githubusercontent.com/50114210/70845378-43837000-1e91-11ea-8572-495f7a5180c5.png)

![image](https://user-images.githubusercontent.com/50114210/70845392-775e9580-1e91-11ea-9fac-ca203c65ef1d.png)

![image](https://user-images.githubusercontent.com/50114210/70845393-7d547680-1e91-11ea-96f6-6dcb5bde1ff1.png)

### eigenface 생성하기

```python
idx = 0 # 테스트하고자 하는 얼굴 영상의 인덱스

## 상위 n개의 eigenvector를 사용하여 eigenface 생성
eigenFaces = pca.inverse_transform(eigenVectors) # 수식 (3)에 해당

## 결과 시각화
plt.subplot(1,2,1)
plt.imshow(faces[idx].reshape((64,64)), cmap='gray')
plt.title('original face')
plt.axis('off')

plt.subplot(1,2,2)
plt.imshow(eigenFaces[idx].reshape((64,64)), cmap='gray')
plt.title('eigenface')
plt.axis('off')

plt.show()
```
![image](https://user-images.githubusercontent.com/50114210/70845382-54cc7c80-1e91-11ea-8b2c-cb701e449164.png)
