---
layout: post
title: "위치 찾기 알고리즘, 스케일에 불변한 특징점 검출"
tags: [Hessain, SUSAN, SIFT, SURF]
categories: [Computer Vision]
---

# 지난 주 내용
4장은 특징점을 검출하는 내용이다. 저번 주에는 내용이 난해했는데, 이번 주에는 더 난해하다.
특징점을 찾는다는 것은 동일한 씬을 찍는데 각도나 크기가 다르게 찍혀진 두 장의 영상에서 A의 영상의 지점이        
B라는 영상의 어느 지점인지 매핑해주는 것을 말한다.   
특징점은 페어관계를 맺어줄 때 기준이 되는 선을 매핑하기 위해서 검출한다.     
여러 장의 영상을 움직여가면서 찍은 것을 붙여서 파노라마 이미지를 만든다던가하는       
코레스펀드 페어를 찾는 것이 중요하다.     


특징점은 모든 방향에서 변화가 큰 점이 좋다.     

### 모라벡 알고리즘
모라벡 알고리즘은     
위 아래 왼쪽 오른쪽을 3 * 3 컨벌루션을 시프트해서 값들을 매트릭스 형태로 구성한다.        
센터를 기준으로 위 아래 왼쪽 오른쪽만 봐도 전반적으로 값이 크게 나타나는 점이 경계일 확률이 높다.      
최소에 해당하는 값을 C로 취하고 값이크면 클수록 특징가능성이 높다고 이야기한다.       
그런데 한 픽셀씩만 보면서 값의 변화율을 살펴본다는 것이 잡음에 대해서 굉장히 취약하다는 단점이있다.      

### 해리스 코너
그래서 해리스코너 방법이 나왔다. 수학적 확장의 개념이 녹아들어 있긴한데,         
중요한 것을 s맵과 비슷한 값이 나온다는 것이다.      
2행 2열짜리 행렬을 모멘트 매트릭스라고 정의하고        
모멘트 매트릭에서 중요한 텀은 y^2 x^2부분이다.     
가로세로로 엣지가 존재하면 전방향으로 엣지가 존재하는 것이기 때문에,       
모든 방향에서 발생가능성이 높기 때문에 특징점으로 삼기 좋다.         
즉 (1, 1), (2, 2)요소가 높아지면 특징점으로서의 가능성이 높아진다.     
대문자 G는 가우시안이다. 영상을 블러시키는 역할을하고      
블러시키는 이유는 잡음을 제거하기 위해서이다.     


2차 모먼트 매트릭스틔 고유값을 구해서 c값을 구한다.     
2행 2열짜리 매트릭스니까 고유값과 고유벡터가 두개 씩 나오는데,      
두개의 고유값에 대해서 특징가능성 c를 구하는 방법은     
고유값과 고유벡터를 계산하는게 계산과정이 복잡한데,       
같은 결과를 쉽게 나오게하는 방법이
(p*q - r^2) - k*(p + q)^2이다.       


이때 임계치를 0.05로하면 특징점이 많이 검출되지 않을 것이고,      
0.01로하면 많이 나올 것이다.     
용어에대한 말을 잠시하자면, 해리스 코너는 코너로서 의미가 있는 것이 아니고       
특징점을 찾는 것에 의미가 있기 때문에            
코너보다는 해리스 피쳐포인트, 해리스 키포인트라고도 한다.      

# 2차 미분을 사용한 방법
### 헤시안 행렬
![image](https://user-images.githubusercontent.com/50114210/66767362-34149480-eeeb-11e9-83f2-678f4c732c10.png)        
해리스는 dx, dy의 1차 미분법을 사용했는데, 2차 미분 방법을 사용해보자.    
y방향의 엣지를 검출하는 마스크는 [-1,  2, -1]일 것이고          
x방향의 엣지를 검출하는 마스크는        
[ -1,           
   2,        
  -1]         
일것이다.        
헤시안 행렬은 dyy, dyx, dyx, dxx로 구성되어있으며 이는 2차 미분한다는 뜻이다.      
dxy는 [[0, -1, 0],        
      [-1, 4, -1],          
       [0, -1, 0]]           
을 마스크로 사용할 것이다.     
가우시안 기호는 블러링을하라는 뜻이고,    
가우시안 수식을 이용해서 영상을 한번 뭉개고 2차 미분값을 구하게 될 것이다.         

### 2차 미분에서 특징 가능성 값 추정
![image](https://user-images.githubusercontent.com/50114210/66767682-ec423d00-eeeb-11e9-9256-4519db254099.png)       
2차 미분에 해당하는 헤시안 매트릭스를 구하고 나면 앞에서 해당하는 c값을 동일하게 구할 수 있다.         
헤시안 행렬식은 말 그대로 행렬식이다.      
가우시안 라플라시안(LOG)라고 정의되어 있는데, 트레이스 값을 c로 쓰게 되어있다.      
|dxx|와 |dyy|가 높으면 해당 픽셀이 특징점일 가능성이 높다는 뜻이고,       
|dxy|가 높으면 특징점일 가능성이 낮다는 뜻이다.       
dxy는 있으나 마나 하기 때문에 가우시안은 빼준 텀을 그냥 없애버렸다.    

# 슈산(SUSAN)
![image](https://user-images.githubusercontent.com/50114210/66768070-b2be0180-eeec-11e9-91e5-cec28dc8c5d1.png)        
상대적으로 심플하다. a를 기준으로 원을 하나 정의한다.     
원 안에 점과 비슷한 밝기 값이 얼마나 있는지 살펴보는 것이다.       
수산의 원리는 뭐냐면 빨간색점과 동일한 밝기를 가지는 비율을 따졌을 때,       
a) 3분의 1이하면 특징점일 가능성이 높다는 것이고
b) 2분의 1정도면 경계일 가능성이 높다.
c) 더 높다면 저주파영역으로 간주한다.       


원을 디지털 영상에서 정의하는 것은 힘들기 때문에      
센터에 해당된 밝기값과 유사도를 보는 것이다.       


if |f(r) - f(r0)| <= t:
  1
else:
  0
  

37개 정도에 18개면 엣지, 6개 정도가 비슷하면 코너      
전부다 비슷하면 아무것도 아니다.     

# 위치 찾기 알고리즘
![image](https://user-images.githubusercontent.com/50114210/66768336-4e4f7200-eeed-11e9-8702-63a129305268.png)           
모라벡) 위 아래 왼쪽 오른쪽 s 3*3을 빼서 제곱한다.      
최소값을 취해서 최소값을 c로 간주하고 노이즈에 민감하다.        
해리스) 2차 모먼트 매트릭스를 구해서 c값을 계산한다.         
헤시안) 2차 미분 방법인 헤시안 매트릭스를 이용해서 헤시안의 디터미넌트를 본다.         
LOG) 라플라시안 가우시안을 보는 방법        
슈산) 원안에 같은 값이 얼마나 있나 보는 방법       

# 비최대 억제
![image](https://user-images.githubusercontent.com/50114210/66768548-c6b63300-eeed-11e9-9097-b35b3fbdb0b8.png)       
영상의 코스트에 해당하는 매트릭스를 순차적으로 탐색하면서       
t라는 임계치보다 크고 4이웃을 검사해서 그것보다도 크면 그것이 특징으로 선택된다.        
그런식으로 로컬 맥시멈을 선택하는 알고리즘을 보여주고 있다.         
이런 것을 비최대 억제라고하고 최대가 아니면 사용하지 않는다.         

# 이동과 회전에 불변인가?
![image](https://user-images.githubusercontent.com/50114210/66768625-f9602b80-eeed-11e9-8426-86fbb481161b.png)           
특징의 위치를 찾는 알고리즘들이 영상이 회전되거나 이동되거나 해도 잘 동작할까?       
당연히 동작해야한다. 왜냐하면 서로 다른 각도, 위치에서 찍혀도       
특징이 사라지는 것은 아니기 때문이다.     
특징점은 잘 나올 것이고 이동이나 회전에 임베리언트하게 잘 동작한다.       

# 스케일에도 불변인가?
![image](https://user-images.githubusercontent.com/50114210/66768718-375d4f80-eeee-11e9-97f3-01177282fc3d.png)       
이동이나 회전에는 큰 영향을 받지않고 알고리즘들이 잘 동작하는데      
그럼 스케일에도 불변할까?        
어떤 사람의 얼굴을 카메라로 멀리서 찍었는데,         
하나는 얼굴이 작게 찍히고 하나는 크게 찍힐 것이다.       
그럼 앞에서 이야기했던 c에 해당하는 cost값에 계산해보면        
두 영상에서 특징점으로 검출되는 애들이 똑같이 나올까? 결론은 잘 안나온다.            
왜냐하면 수산방법 같은 애들은 원의 크기를 정의하는데       
삼각형이 작을 때와 클 때 사용하는 원이 다를 것이기 때문이다.         

# 거리에 따른 스케일 변화
![image](https://user-images.githubusercontent.com/50114210/66768860-8acf9d80-eeee-11e9-8339-fecfbdab4256.png)       
10분의 1씩 줄여보면 봉오리에 해당하는 지점을 산봉오리가 하나의 픽셀로 정의될 수 있다.      
근데 산봉오리는 어디인가? b의 축소버전은 크게 나올 것이다.        
근데 오리지널은 크게나오지 않는다 그냥 평평하기 때문이다.              
산봉오리 지점이 코너 포인트로 간주가 될 수 있지만        
오리지널에서는 그냥 엣지로 구분할지도 모른다.        
그래서 크기가 다르면 성능이 다르게 검출될 것이다. 즉, 스케일링에는 임베리언트하지 않다.         

# 다중 스케일 연산을 구현하는 두 가지 방법
![image](https://user-images.githubusercontent.com/50114210/66769266-a2f3ec80-eeef-11e9-9da9-bce0c081e8d7.png)      
앞에서 이야기한 거은 이동이나 회전에는 임베리언트하지만       
스케일에는 베리언트하다는 것이었다.      
우리는 사이즈가 바뀌어도 잘 동작할 수 있게하는 알고리즘이 필요하다.       
3차원 공간에서 극점이 필요하다. 어떻게 해서 3차원이 되었나?     
가로, 세로, 스케일 축으로 3차원으로 정의한다.       
스케일 축을 포지셔닝해서 각 스케일에 대해서도 특징점이 검출되는지 알아본다.         
어느 스케일에서 영상이 나왔다. 특징점의 위치를 x, y, s로 저장한다.           
그럼 어떤 영상이 주어졌을 때 스케일을 특징점으로 잘 검출되는 스케일로 맞추고 검출한다.         

# 영상을 줄인다는 것
스케일을 줄여나가는 방법을 다중 스케일이라고 한다.         
다양한 영상을 스케일을 줄여가면서 만드는 방법이다.            
영상을 줄인다는 것은 영상의 고주파 성분이 사라진다는 의미를 가진다.      
이게 무슨 의미냐면 화소를 압축할때 평균을 내던가 건너 뛰던가 할텐데        
이런 과정에서 고주파 성분이 날라가게 된다는 것이다.             
나이키스트의 샘플링 이론에서는 최대 고주파 성분의 주기의 두배만큼 잘게 쪼개야한다.      
그래야 성분을 잘 표현할 수 있다고 말한다.       
그렇게 샘플링정도가 딱 적당했던 영상이 있었는데        
영상의 크기를 줄이게되면 샘플링이 완벽하게 되지 못하고 디테일한 정보가 사라지게된다.         

# 가우시안 스무딩을 사용하여 스케일 다운
![image](https://user-images.githubusercontent.com/50114210/66769655-9cb24000-eef0-11e9-8a9e-90f38d592ace.png)        
가우시안 스무딩을 이용하여 스케일이 다운된 영상을 구하는 방법이있다.          
영상의 해상도를 줄였다가 늘리게 되면 손실된 고주파 정보는 다시 복원할 수 가 없다.       
없는 것을 만들어서 채운다면 사라진 고주파 성분이 다시 복구 될 수는 없을 것이다.      
영상을 축소시킨다는 것은 영상을 흐리게 만드는 효과를 가져온다.      
이러한 아이디어 착안하여 가우시안 스무딩으로 영상을 흐리게한다.         
가우시안 수식이 시그마에 따라서 가우시안이 완만해져서 더 많이 영상이 뭉개진다.      
영상의 사이즈가 줄어든다면 커널 사이즈도 비례해서 줄여야하지만         
영상의 사이즈마다 조절하는 것은 프로그래머들이 굉장히 싫어할테니       
해상도를 동일하게 설정하고 마스크의 크기를 동일하게 유지시킨다.       
t값이 커진다는 것은 가우시안 분포값을 키운다는 것이고       
더 많이 뭉개는 것은 점점 저주파 성분을 남기고 고주파 성분을 줄이는 것을 말한다.       

# x축에서 지역 극점 탐색
![image](https://user-images.githubusercontent.com/50114210/66769927-53162500-eef1-11e9-96bd-4c3c4fa27608.png)       
방금 위에서 말한 시그마의 값에 변화에 따라 t축의 변화가 있게된다.       
근데 t축에 대해서 시그마 값을 바꿔가면서 영상의 특징점을 뽑아보자.      
그래서 정규 라플라시안을 정의했다. x2차 미분, y2차미분, 시그마만큼 뭉개기         
뭉개게되면 고주파성분이 손실되어서 원본 영상의 특징점들의 값과         
어느정도 일치하게 스케일링해주기 위해 시그마 제곱을 곱해준다.              
영상에서는 한 덩어리를 블랍이라고한다.     
시그마가 1, 2, 3, 4, 5 일 때 가우시안 수식의 분포를 키우면서       
분포가 커지면 커질 수록 더 많이 뭉개지게된다.          
이 짓을 1간격으로 하는 것이 아니라 0.01 간격으로하고       
블랍 영상을 생성하고, 정규 라플라시안 값을 동일한 지점에서 측정해본다.         
근데 극점을 계산해보면 c에 해당되는 값이 영상을 뭉개는 시그마 값의 변화에 따라        
측정값이 다르게 나온다는 것이다.          
극점이 나왔으니까 어떤 영상에 대해서 시그마가 3.59가 되는 수준으로 맞춰주자.           














