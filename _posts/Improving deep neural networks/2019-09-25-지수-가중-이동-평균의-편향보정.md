---
layout: post
title: "지수 가중 이동 평균의 편향보정"
tags: [Bias Correction]
categories: [Improving deep neural networks]
---

# 학습 목표
편향 보정에 대해서 알 수 있다.

# 핵심 키워드
편향 보정(Bias Correction)

# 학습 내용
* 편향 보정으로 평균을 더 정확하게 계산할 수 있습니다.
* 저번 시간에 따른 지수평균식대로라면 t=1 일때 (1-β)를 곱한 값이 첫번째 값이 되는데, 이는 우리가 원하는 실제 v1값과 차이가 나게 된다.
* 따라서 vt(1-β^t)를 취해서 초기 값에서 실제값과 비슷해지게 합니다.
* 보통 머신러닝에서 구현하지는 않습니다. 시간이 지남에 (1-β^t)는 1에 가까워져서 저희가 원하는 값과 일치하게 되기 때문입니다.
* 그렇지만 신경이 쓰인다면 구현하는게 옳습니다.

# 인트로
지수가중평균을 어떻게 구현하는지 배웠습니다.       
편향 보정이라고 불리는 기술적인 세부 사항으로 평균을 더 정확하게 계산할 수 있습니다.       
어떻게 작동되는지 살펴봅시다.

# 편향보정된 그래프와 아닌 그래프
![image](https://user-images.githubusercontent.com/50114210/65593005-a10ecb80-dfca-11e9-94aa-7c8ae66386dd.png)    
지난 글에서 β가 0.9일 때의 그래프와 β가 0.98일 때의 그래프를 살펴보았습니다.        
그러나 여기 작성된대로 공식을 구현하면 β가 0.98일 때 초록색 곡선을 얻지 못할 것입니다.       
![image](https://user-images.githubusercontent.com/50114210/65593065-bedc3080-dfca-11e9-9899-efd4237bbd39.png)    
여기 있는 보라색 곡선을 얻게 될 것입니다.       
보라색 곡선이 매우 낮은 곳에서 시작한다는 것이 보이실 겁니다. 이를 고쳐보도록 하겠습니다.          

# 편향 보정이 안 되었을 때의 값
![image](https://user-images.githubusercontent.com/50114210/65593321-31e5a700-dfcb-11e9-86d3-7e45cf613906.png)      
이동평균을 구할 때 v_0는 0으로 초기화하고 v_1은 0.98*v_0 + 0.02*θ_1입니다.          
그러나 v_0가 0이기 때문에 0.98*v_0항은 사라지게 됩니다. v_1은 그냥 0.02*θ_1이 됩니다.           
따라서 첫 번째 날의 온도가 화씨 40도면 v_1의 값은 0.02*40인 8이 될 것입니다.        
값이 훨씬 더 낮아져서 첫 번째 날의 온도를 잘 추정할 수 없습니다.           
v_2는 0.98*v_1 + 0.02*θ_2가 될 것입니다.        
v_1 값을 여기에 대입하면 v_2의 값은 0.98*0.02*θ_1 + 0.02*θ_2가 됩니다. 이것은 0.0196*θ_1 + 0.02*θ_2입니다.         
θ_1과 θ_2가 양수라고 가정하면 v_2를 계산한 값은 θ_1이나 θ_2보다 훨씬 더 작아질 것입니다.             
한 해의 첫 두 날짜를 추정한 값이 좋지 않은 추정이 됩니다.        

# 편향 보정
![image](https://user-images.githubusercontent.com/50114210/65593367-4c1f8500-dfcb-11e9-8f58-03c8edba8d6f.png)        
따라서 이 추정값이 더 나은 값이 될 수 있도록 수정하는 방법이 있습니다.       
특히 추정의 초기 단계에서 더 정확하게 보정할 수 있습니다.        
v_t를 취하는 대신에 v_t / (1-β)^t를 취합니다. t는 현재의 온도입니다.         
예시를 들어 살펴보면 t가 2일 때 1-β^t는 1-(0.98)^2와 같습니다. 이 값을 계산하면 0.0396과 같습니다.       
따라서 둘째 날의 온도를 추정한 값은 v2를 0.0396으로 나눈 값과 같습니다.         
이 값은 0.0196*θ_1 + 0.02*θ_2를 0.0396으로 나눈 값과 같습니다.             
따라서 이것은 θ_1과 θ_2의 가중평균에 편향을 없앤 값이 됩니다.        
따라서 t가 더 커질수록 β^t는 0에 가까워집니다.         
따라서 t가 충분히 커지면 편향 보정은 그 효과가 거의 없어집니다.         

# 편향 보정의 영향 
![image](https://user-images.githubusercontent.com/50114210/65593065-bedc3080-dfca-11e9-9899-efd4237bbd39.png)            
t가 커질 때 보라색 곡선과 초록색 곡선이 거의 겹치는 이유입니다.        
그러나 초기 단계의 학습에서 편향 보정은 더 나은 온도의 추정값을 얻을 수 있도록 도와줍니다.           
보라색 선에서 초록색 선으로 갈 수 있게 합니다.         

# 아웃트로
머신러닝에서 지수가중평균을 구현하는 대부분의 경우 사람들은 편향 보정을 거의 구현하지 않습니다.         
왜냐하면 초기 단계를 그냥 기다리고 편향된 추정이 지나간 후부터 시작합니다.        
그러나 초기 단계의 편향이 신경쓰인다면 편향 보정은 초기에 더 나은 추정값을 얻는데 도움이 될 것입니다.          
