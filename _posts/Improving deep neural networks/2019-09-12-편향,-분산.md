---
layout: post
title: "편향, 분산"
tags: [Bias, Variance, Bias-Variance trade-off]
categories: [Improving deep neural networks]
---

# 학습 목표
편향-분산 트레이드오프에 대해 배웁니다

# 핵심 키워드
편향(Bias)
분산(Variance)
편향-분산 트레이드 오프(Bias-Variance trade-off)

# 학습 내용
* 편향-분산 트레이드오프

|높은 편향(high bias)|과소 적합(underfitting)|
|:----:|:----:|
|알맞음(just right)|-|
|높은 분산(high variance)|과대 적합(overfitting)|

* 훈련 세트와 개발 세트의 관계

||높은 분산(과대 적합)|높은 편향(과소 적합)|높은 편향 & 높은 분산|낮은 편향 & 낮은 분산|
|:----:|:----:|:----:|:----:|:----:|
|훈련 세트|1%|15%|15%|0.5%|
|개발 세트|11%|11%|30%|1%|

* 가정 : 인간 수준의 성능이 기본으로 되어야 합니다. 이번 예제에서는 개와 고양이를 분류할 때 인간 수준의 성능은 0%에 가까울 것입니다. 조금 더 일반적으로 이야기 하면, 베이지안 최적 오차가 0%라는 가정이 깔려 있습니다.
* 베이지안 최적 오차 개념은 차후에도 배웁니다. 너무 걱정 안 하셔도 됩니다.

# 인트로
대부분의 유능한 머신러닝 실무자들은 편향과 분산에 대한 수준 높은 이해를 가지고 있는 경우가 많습니다.     
변향과 분산에 대한 개념은 배우기는 쉽지만 완벽히 이해하기는 어렵습니다.    
편향과 분산의 기본 개념이 예상보다 더 미묘하기 때문입니다.     
딥러닝 시대의 또 다른 트렌드로는 편향-분산 트레이트오프에 관한 더 적은 논의입니다.    
딥러닝 시대에 여전히 편향과 분산에 관한 이야기는 하지만 편향-분산 트레이드오프에 관한 이야기는 더 적어졌습니다.    
이것이 무슨 의미인지 알아봅시다.

# 편향과 분산
### 편향이 높은 과소 적합
![image](https://user-images.githubusercontent.com/50114210/64793309-d45a5f00-d5b5-11e9-984b-79bf64dbad20.png)     
위와 같은 데이터가 있다고 했을 때 데이터네 맞는 직선을 그려봅시다.    
로지스틱 회귀라고 했을 때 데이터에 잘 맞는 형태는 아닙니다.    
높은 편향값의 클래스이므로 데이터의 과소적합이라고 말합니다.     
            
                    
                    

### 분산이 높은 과대 적합
![image](https://user-images.githubusercontent.com/50114210/64793369-e89e5c00-d5b5-11e9-9b3f-cd5adf821d53.png)     
반대로 깊은 신경망 혹은 많은 은닉 유닛이 있는 신경망을 사용하는 경우에 데이터를 완벽하게 맞출 수는 있지만     
이것 역시 적절하지 않아보입니다.    
따라서 이것은 높은 분산의 클래스이고 데이터의 과대적합이라고 합니다.     
            
                    
                    



### 편향과 분산이 낮은 적절한 분류기
![image](https://user-images.githubusercontent.com/50114210/64793409-f94ed200-d5b5-11e9-8fe3-8bca819b088f.png)    
그럼 이 사이에 중간 단계의 복잡함을 가지는 분류기가 있을 겁입니다.    
이런 형태의 곡선이 데이터에 훨씬 적합하게 보입니다.     
이 사이에 있는 형태를 딱 맞는 형태라고 부르겠습니다.   
따라서 특성 x1과 x2만을 갖는 2차원의 예제에서는 데이터를 나타내고 편향과 분산을 시각화할 수 있습니다.     
높은 차원의 문제에서는 데이터를 나타내거나 결정 경계를 시각화할 수 없습니다.    
대신에 편향과 분산을 이해하기 위해 살펴볼 몇가지 기법들이 있습니다.
            
                    
                    

# 고양이와 개 예제
![image](https://user-images.githubusercontent.com/50114210/64795501-251f8700-d5b9-11e9-9a3f-5714aa44e658.png)     
고양이 사진 분류 예제로 계속하면 고양이를 양성 샘플 강아지를 음성 샘플이라고 합시다.     
편향과 분산을 이해하기 위한 중요한 두 가지 숫자는 훈련 세트 오차와 개발 세트 오차가 있습니다.     
논증을 위해 고양이 사진을 인식하는 것은 사람들이 완벽히 할 수 있는 것이라고 가정해봅시다.     
            
                    
                    

### 개발 세트에서 높은 오차를 가지는 과대 적합
![image](https://user-images.githubusercontent.com/50114210/64795682-7465b780-d5b9-11e9-914f-238bf61eeff5.png)     
훈련 세트 오차가 1%라고하고 개발 세트 오차는 11%라고 해봅시다.    
따라서 이 같은 예제에서 훈련 세트에서는 매우 잘 분류됐지만 상대적으로 개발 세트에서는     
잘 분류되지 못한 경우입니다.    
즉 훈련 세트에 과대적합이 되어서 개발 세트가 있는 교차 검증 세트에서 일반화되지 못한 경우입니다.     
따라서 이런 경우의 예제는 높은 분산을 갖는다고 말합니다.     
따라서 훈련 세트 오차와 개발세트 오차를 살펴봄으로써 알고리즘이 높은 분산을 갖는다는 것을 진단할 수 있게 됩니다.    
            
                    
                    

### 훈련 세트와 개발 세트 비슷하게 안 맞는 높은 편향
![image](https://user-images.githubusercontent.com/50114210/64795737-8cd5d200-d5b9-11e9-9dd9-6a318669a796.png)     
이제 훈련 세트와 개발 세트 오차를 측정했는데 다른 결과를 얻었다고 해봅시다.    
훈련 세트 오차는 15%이고 그리고 개발 세트 오차는 16%라고 해봅시다.      
그럼 이 알고리즘은 훈련 세트에 대해서도 잘 작동되지 않는 것처럼 보입니다.
훈련 데이터에 대해서도 잘 맞지 않는다면 데이터에 과소적합한 것입니다.     
이 알고리즘은 높은 편향을 갖습니다.        
그렇지만 합리적인 수준의 개발 세트에서 일반화되고 있습니다.     
개발 세트의 성능이 훈련세트보다 1% 밖에 나쁘지 않으니까요.    
따라서 이 알고리즘은 높은 편향의 문제를 가지고 있습니다.     
훈련 세트에도 잘 맞지 않으니까요.    
            
                    
                    

### 훈련 세트도 높지만 개발 세트는 높은 높은 편향과 높은 분산을 가진다.
![image](https://user-images.githubusercontent.com/50114210/64795890-c9a1c900-d5b9-11e9-9d35-30b779cc252e.png)     
여기 또 다른 예제입니다.    
15%의 훈련 세트 오차를 가정합시다. 꽤 높은 편향입니다.    
그러나 개발 세트에서 평가했을 때 훨씬 더 나쁜 오차를 가집니다. 30%라고 해봅시다.      
이 경우에 알고리즘이 높은 편향을 갖는다고 진단내릴 것입니다. 훈련 세트에 잘 맞지 않으니까요.     
또한 높은 분산을 갖습니다. 두 값 모두 최악의 경우네요.      
            
                    
                    

### 편향과 분산이 모두 낮은 만족스러운 경우
![image](https://user-images.githubusercontent.com/50114210/64795963-ee963c00-d5b9-11e9-8481-bc2a6b62d753.png)     
마지막으로 다룰 예제는 훈련 세트 오차는 0.5%이고 개발 세트 오차는 1%인 경우입니다.    
사용자는 오직 1%의 오차만 있는 고양이 분류기에 만족할 것입니다.    
이 분류기의 편향과 분산이 낮기 때문입니다.     
            
                    
                    

### 오차에 따라 편향과 분산에 대해 감을 잡을 수 있다
중요한 것은 훈련 세트 오차를 확인함으로써 최소한 훈련 데이터에서 얼마나 알고리즘이 적합한지에 감을 잡을 수 있다는 것입니다.     
편향 문제가 있는지 알 수 있씁니다. 훈련 세트에서 개발 세트로 갈 때 오차가 얼마나 커지는지에 따라서     
분산 문제가 얼마나 나쁜지에 대한 감을 잡을 수 있습니다.     
훈련 세트에서 개발 세트로 일반화를 잘 하느냐에 따라 분산에 대한 감이 달라집니다.   
            
                    
                    

# 높은 편향과 높은 분산의 경우
![image](https://user-images.githubusercontent.com/50114210/64796128-30bf7d80-d5ba-11e9-8796-1926c7a79ef7.png)      
선형의 분류기는 데이터에 과소적합하기 때문에 높은 편향을 갖습니다.    
따라서 이 분류기는 거의 선형이고 데이터에 과소적합할 것입니다.     
그러나 만약에 분류기가 이상하게 동작해서 일분의 데이터에 과대적합한다면      
보라색으로 그린 분류기는 높은 편향과 높은 분산을 갖게 됩니다.    
선형의 분류기는 이런 2차 곡선에 맞지 않으므로 높은 편향을 갖습니다.    
그러나 중간에 너무 많은 굴곡을 가져서 이 샘플과 이 샘플이 과대적합됩니다.     
따라서 이 분류기는 거의 선형이지만 곡선이나 이차 함수가 필요하기 때문에 높은 편향을 갖습니다.     
또한 중간에 잘못 라벨링된 샘플을 맞추기 위해 너무 많은 굴곡을 갖기 때문에 높은 분산을 갖게 됩니다.    
이 예제는 이차원에서 고안된 예제입니다.    
그러나 매우 높은 차원의 입력에서는 어떤 영역은 높은 편향을 갖고 어떤 영역은 높은 분산을 갖게 됩니다.    
따라서 그럴 것 같지 않은 높은 차원의 입력에서도 이런 모습이 나타날 수 있습니다.    
            
                    
                    

# 아웃 트로
훈련 세트와 개발 세트의 알고리즘 오차를 살펴봄으로써     
높은 편향, 높은 분산, 혹은 둘 다의 문제를 갖는지 진단하는 방법을 배웠습니다.    







