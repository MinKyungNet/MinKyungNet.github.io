---
layout: post
title: "하이퍼파라미터 튜닝 실전"
tags:: [Hyperparameter]
categoires: [Improving deep neural networks]
---

# 학습 목표
하이파파라미터 튜닝 방법을 배운다.

# 핵심 키워드
하이퍼파라미터(Hyperparameter)

# 학습 내용
* 하이퍼파라미터 튜닝 방법은 두 가지가 있습니다.
* 모델 돌보기(baby sitting one model) = 판다 접근
  - 컴퓨터의 자원이 많이 필요하지 않거나, 적은 숫자의 모델을 한번에 학습시킬 수 있을때 사용합니다.
  - 하나의 모델로 매일 성능을 지켜보면서, 학습 속도를 조금씩 바꾸는 방식입니다.
* 동시에 여러 모델 훈련(Training many models in parallel) = 캐비어 접근
  - 컴퓨터의 자원이 충분히 많아 여러 모델을 한 번에 학습 시킬 수 있을 때 사용합니다.
  
# 인트로
이전에는 하이퍼파라미터를 탐색하는 방법을 설명드리지 않았는데요.        
하이퍼파라미터 탐색을 마무리하기 앞서 탐색을 어떻게 할 수 있는지        
몇 가지 팁을 알려드리고자 합니다.          

# 빌드업
오늘날 딥러닝은 여러 분야에 적용되고 있습니다.         
한 어플케이션에서 얻은 하이퍼파라미터에 대한           
직관이 다른 영역에서 쓰일 수도, 아닐 수도 있습니다.             
서로 다른 어플리케이션 영역 간에 공유되는 것들이 있는데요.             
예를 들면 컴퓨터 비전 커뮤니티에서 발전된 컨브넷이나 레스넷 등이 있는데요.            
이것들은 음성에 잘 적용되고 있죠 그리고 이 음성에서 발전된 아이디어들이          
자연어 처리에서도 잘 적용되고 있는 것을 봤습니다.            
즉 딥러닝 분야의 사람들이 다른 영역에서 영감을 얻기 위해         
그 분야의 논문을 점점 많이 찾아 읽고 있습니다.              
하지만 하이퍼파라미터를 찾는 과정은 그렇지 못하다는 직관을 얻었습니다.             
로지스틱 문제 하나만 보더라도 여러분이 좋은 하이어파라미터를 찾았다고 할 때            
알고리즘을 계속 발전시키거나 몇 달에 걸쳐 데이터가 바뀔 수도 있고요.            
데이터 센터의 서버를 업그레이드 시킬 수도 있겠죠.           
이러한 변화들 때문에 여러분이 찾았던 하이퍼파라미터가 녹스는 겁니다.             
그래서 다시 시험해보거나 하이퍼파라미터들이 아직도 만족할만한 결과를           
내는지 몇 달마다 재평가하기를 권합니다.             
결국 사람들이 하이퍼파라미터를 찾을 때 크게 두 가지 서로 다른 방법을 사용하는 것을 봤습니다.         

# 하나의 모델을 꼼꼼히 학습
![image](https://user-images.githubusercontent.com/50114210/65826381-f5fa5c80-e2be-11e9-965b-6e0a2b122aea.png)          
하나는 모델 돌보기인데요 데이터는 방대하지만             
CPU나 GPU 등 컴퓨터 자원이 많이 필요하지 않아서               
적은 숫자의 모델을 한번에 학습시킬 수 있을 때 사용합니다.              
이런 경우에 학습 과정에서 모델 돌보기를 하는데요.             
예를 들어 0일차에 무작위하게 매개변수를 설정하고 학습을 시작했습니다.           
그러면 학습곡선에서 비용함수 J나 개발 세트의 오차가 하루가 다르게 점진적으로 감소할 겁니다.         
1일차 끝 무렵에 학습이 꽤나 잘 되었다면 학습 속도를 조금 올려서        
조금 더 나은지 보자고 말할 수 있겠죠. 이런 식으로 성능을 올려가는 겁니다.          
그리고 2일차에도 꽤 좋은 성과를 내고 있는 것 같습니다.         
여기서도 모멘텀을 약간 올리거나 학습 속도를 약간 낮출 수 있겠죠.         
그리고 3일차에 들어섭니다. 다시 결과를 살펴보겠죠?            
그렇게 하이퍼파라미터를 계속 조절하다보면          
어떤 날에 학습 속도가 너무 커서 몇 일 전으로 돌아가기도 하겠죠.          
이렇게 며칠, 몇 주에 걸쳐 매일 모델을 돌보며 학습시키는 겁니다.         
이게 한 가지 접근 방법입니다. 모델 돌보기는 성능을 잘 지켜보다가          
학습 속도를 조금씩 바꾸는 방식인 거죠.             
이 방식은 여러 모델을 동시에 학습시킬 컴퓨터 자원이 충분치 않을 때 사용합니다.           

# 여러 모델을 한번에 학습
![image](https://user-images.githubusercontent.com/50114210/65826386-07dbff80-e2bf-11e9-90fd-f9db207ad51a.png)          
다른 접근은 여러 모델을 함께 학습시키는 건데요.          
여러분이 갖고 있는 하이퍼파라미터를 며칠에 걸쳐 스스로 학습하게 합니다.          
그럼 이런 학습 곡선이 얻어지겠죠? 비용 함수 J를 그린 것일 수도 있고요.          
학습 오차나 개발 세트의 오차 등 어떤 수치를 나타내고 있을 겁니다.            
그리고 동시에 다른 모델의 다른 하이퍼파라미터 설정을 다루기 시작합니다.            
두 번째 모델을 다른 학습 곡선을 그리겠지요?         
그리고 동시에 세 번째 모델도 학습시킵니다. 학습 곡선이 그려지고요.          
또 다른 것은 발산한다고 합시다. 이렇게 서로 다른 모델을 동시에 학습시키는 겁니다.            
이 주황색 선들도 서로 다른 모델을 나타냅니다.            
이 방법을 쓰면 여러 하이퍼파라미터 설정을 시험해볼 수 있죠.             
그리고 마지막에는 최고 성능을 보이는 것을 고르는 겁니다.           

# 판다
![image](https://user-images.githubusercontent.com/50114210/65826388-10343a80-e2bf-11e9-9dd6-d229529caec8.png)          
비유를 하자면 왼쪽 접근은 판다 같습니다.        
팬더는 한 번에 한 마리 씩만 아이를 갖죠.          
그리고 아기 팬더가 살아남을 수 있도록 정말 많은 노력을 기울입니다.            
말 그대로 모델이나 아기 팬더를 '돌보기'하는 거죠.        

# 캐비어
![image](https://user-images.githubusercontent.com/50114210/65826393-1cb89300-e2bf-11e9-9020-285e6059a1f8.png)          
오른쪽 접근은 제가 캐비어 전략이라고 부르는데요.          
물고기랑 비슷하기 때문입니다. 한 철에 1억개의 알을 품는 물고기가 있는데요.          
물고기가 번식을 하는 과정은 하나에 많은 집중을 쏟기보다.          
하나 또는 그 이상이 더 잘 살아남기를 바라며 그저 지켜보는 것입니다.         
제가 생각컨대 이것은 포유류의 번식과 어류, 파충류의 번식의 차이인 것 같아요.           
더 기억하기 쉽고 재밌으니 이제부터 판다 접근, 캐비어 접근이라고 부르겠습니다.         

# 어떤 방법을 선택해야할까
이 두 접근 중에 뭘 선택할지는 컴퓨터 자원의 양과 함수 관계에 있습니다.           
만약 여러 모델을 동시에 학습시키기에 충분한 컴퓨터를 갖고 있다면          
물론 캐비어 접근을 사용해서 서로 다른 하이퍼파라미터를 시험해볼 수 있겠죠.         
하지만 온라인 광고나 컴퓨터 비전 어플리케이션 등           
많은 데이터가 쓰이는 곳에서는 학습시키고자 하는 모델이 너무 커서          
한 번에 여러 모델을 학습시키기 어렵습니다.          
물론 어플리케이션에 따라 큰 차이가 있지만 팬더 접근을 주로 사용하더군요.           
하나의 모델에 집중해 매개변수를 조금씩 조절하며           
그 모델이 잘 작동하게끔 만드는 것이죠.          
하지만 팬더 접근에서도 한 모델이 잘 작동하는지 확인한 뒤에         
2주, 3주 후에 다른 모델을 초기화해서 다시 돌보기를 할 수 있습니다.          
팬더가 일생에 여러 마리의 새끼를 돌보는 것처럼요.            
한 번에는 하나 혹은 아주 적은 숫자의 새끼만 돌보지만 말이죠.             

# 아웃트로
이 영상을 통해 여러분이 하이퍼파라미터 탐색에        
대한 좋은 감을 얻으셨으리라 믿습니다.             
그리고 하이퍼파라미터에 상관없이 튼튼한 신경망을 만드는 방법이 있습니다.           
모든 신경망에 적용되는 것은 아닙니다만 적용이 가능하다면          
하이퍼파라미터 탐색이 훨씬 쉽고 빨라집니다.           
