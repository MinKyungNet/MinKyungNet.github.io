---
layout: post
title: "테스트시의 배치 정규화"
tags: [Batch Normalization, Exponentially Weighted Average]
categories: [Improving deep neural networks]
---

# 학습 목표
테스트시 배치 정규화가 작동하는 원리를 파악한다.

# 핵심 키워드
* 배치 정규화(Batch Normalization)
* 지수 가중 이동 평균(Exponentially weighted Average)

# 학습 내용
* 이전 강의에서 사용된 배치 정규화의 수식입니다.          
![image](https://user-images.githubusercontent.com/50114210/65935466-32ab8c80-e454-11e9-80e3-0b8929b12388.png)     
* 테스트 시에는 배치가 하나이기 때문에 평균과 분산을 계산할 수 없습니다. 따라서, 학습시에 사용된 미니배치들의 지수 가중 이동 평균을 추정치로 사용합니다.

# 인트로
배치 정규화는 한 번에 하나의 미니배치 데이터를 처리합니다.        
하지만 테스트에서는 한 번에 샘플 하나씩을 처리해야 하죠.        
이를 위해 신경망을 학습시키는 법을 살펴봅시다.      

# 배치 정규화 식
![image](https://user-images.githubusercontent.com/50114210/65935683-ec0a6200-e454-11e9-8b4c-045d4cfce361.png)       
여기에 나와있는 식들은 학습 중 배치 정규화를 위해 사용했던 식들입니다.          
단일 미니 배치에서 평균을 구하기 위해 z^(i) 값을 합했습니다.       
미니 배치 안의 샘플들을 모두 합하는 거죠.        
여기에서 m은 미니 배치 안의 샘플 수이지 전체 훈련 세트에서의 개수가 아닙니다.       
그리고 분산을 계산할 수 있고요.            
평균과 표준편차로 크기를 조정해서 z_norm도 계산할 수 있죠.        
ε은 수학적 안정성을 위해 추가되었습니다.          
z~는 z_norm을 γ와 β을 써서 조정한 것입니다.        
여기에서 이 식을 계산하는 데 필요한 μ와 σ^2은.        
미니 배치 안에서 계산되지만 테스트 과정에서는 64, 128, 256개 등의         
샘플를 포함하는 미니 배치가 없으므로 동시에 처리할 수 없습니다.           
따라서 μ와 σ^2을 처리할 다른 방법이 필요합니다.          
만약 하나의 샘플만 있을 때 그 샘플의 평균과 분산을 구하는 것은 말이 안 되니까요.            

# 테스트시에는 정해진 μ와 σ^2을 사용하자
![image](https://user-images.githubusercontent.com/50114210/65935707-06dcd680-e455-11e9-9562-f160ebc7820f.png)          
그럼 테스트 과정에서 신경망을 어떻게 적용할 수 있을까요?         
각각 독립된 μ와 σ^2의 추정치를 사용하면 됩니다.      
전형적인 배치 정규화를 구현할 때는 여러 미니 배치에 걸쳐서 구한        
지수가중평균을 추정치로 사용합니다. 다시 깔끔하게 설명을 드리도록 하죠.       

# μ와 σ^2의 지수 가중 이동 평균 구하기
![image](https://user-images.githubusercontent.com/50114210/65935740-24aa3b80-e455-11e9-8288-6aec87981b35.png)    
어떤 층 L을 고릅시다. 그리고 미니 배치 X^{1}, X^{2} 등과       
대응하는 값 Y가 있다고 하죠.         
L 층에 대해서 X^{1}을 학습시킨다면 μ^[l]을 얻겠죠?       
여기서는 μ^{1}[l], 그 층의 첫 번째 미니 배치라고 쓰겠습니다.           
그리고 두 번째 미니 배치에 대해서도  학습시키면 두 번째 μ 값을 얻을 수 있겠죠.           
그리고 이 은닉층의 세 번째 미니 배치에 대해서          
세 번째 μ 값을 얻을 수도 있습니다.          
우리가 봤듯이 지수가중평균을 이용해서 θ_1, θ_2, θ_3의 평균을 계산한다고 합시다.           
현재 온도의 기하급수적 평균을 계산했을 때        
이 평균 벡터에서 가장 최근의 평균값이 뭐였는지 기록해야 했죠.         
그러면 지수가중평균이 그 은닉층의 z 값 평균의 추정치가 되는 겁니다.           
비슷하게 지수가중평균을 이용해서 σ^2의 값을 추적할 수도 있습니다.             
그 층의 첫 번째 미니 배치에서 σ^2을 구하고          
두 번째 미니 배치에서 반복하는 거죠.        
이렇게 μ와 σ^2의 이동 평균을 구할 수 있는 겁니다.           
신경망에서 서로 다른 미니 배치로 학습시킨 각 층에 대해서 말이죠.           

# 테스트 시에는 하나의 데이터에 대해 정규화
![image](https://user-images.githubusercontent.com/50114210/65935775-43103700-e455-11e9-8b11-590449eb0a78.png)          
그러면 테스트 과정에서 여러분은 z_norm을 계산만 하면 됩니다.         
여러분이 갖고 있는 z 값과 μ와 σ^2의 지수가중평균을 이용해서요.             
가장 최근의 값이 뭐였든 간에 여기서 값을 조정하는데 쓰이는 거죠.           
그리고 테스트 샘플에 대해서 z-를 계산할 수도 있겠죠.          
방금 왼쪽에서 계산한 z_norm과 신경망 학습 과정에서 학습시킨        
β, γ 매개변수를 이용해서 말이죠.          
여기서 알아두어야 할 것은 학습 과정 중에는        
μ와 σ^2는 64나 256개 등의 미니 배치로 계산하지만         
테스트할 때는 한 번에 샘플 하나를 처리해야 합니다.         
μ와 σ^2를 훈련 세트로부터 추정해야 합니다.           
여러 가지 방법이 있는데요 이론적으로는 훈련 세트를 이용해          
최종적으로 학습한 신경망의 μ와 σ^2를 얻을 수도 있고요.          
그러나 실제로는 지수가중평균을 사용합니다.         
μ와 σ^2가 학습하면서 가진 값을 추적하면서 말이죠.     
지수가중평균을 이용하는 것을 달리 이동 평균이라고도 합니다.         
μ와 σ^2의 추정치를 대충 결정한 뒤 테스트 과정에서 사용하는 것이죠.          
은닉층의 z 값을 조정할 때 필요하니까요.          
실제로 이 방법은 μ와 σ^2를 추정하는데 꽤나 안정적입니다.         

# 아웃트로
이렇게 배치 정규화에 대한 내용이 끝났습니다.    
이걸 이용하면 더 깊은 신경망을 학습시키고         
학습 알고리즘을 더 빨리 실행할 수 있을 겁니다.         
