---
layout: post
title: "적절한 척도 생성하기"
tags: [Hyperparameter, Learning rate]
categories: [Improving deep neural networks]
---

# 학습 목표
하이퍼파라미터 선택에 적절한 척도를 정하는 방법을 배운다.

# 핵심 키워드
* 하이퍼파라미터(Hyperparameter)
* 학습률(Learning rate)

# 학습 내용
* 무작위로 뽑는 것이 합리적인 하이퍼파라미터들이 있습니다. 예를 들어, 은닉 유닛의 수, 은닉층의 수
* 하지만, 학습률의 경우 다릅니다.
  - 1과 0.0001 사이의 값중에 균일하게 무작위 값을 고르게 되면, 90%의 값이 1과 0.1사이에 존재하기 때문에, 공평하다고 할 수 없습니다.
  - 따라서 선형척도대신 로그척도에서 하이퍼파라미터를 찾는 것이 합리적입니다.
  - 위 예시에 따르면 0과 -4 사이에 균일하게 무작위로 고르고 10의 지수로 바꿔주는 것입니다.
* 다른 예시로, 지수 가중 이동 평균에서 사용되는 베타입니다. 마찬가지로 0.9와 0.999사이의 값을 탐색하는 것은 비합리적이기 때문에 1-베타를 취해준 후, 위의 예시와 마찬가지로 로그척도에서 무작위 값을 선택해여 탐색합니다.
* 왜 선형척도에서 샘플을 뽑은 것이 안 좋을까요?
  - 그 이유는 위의 값들은 1에 가까울 수록 알고리즘 결과에 더 큰 영향을 끼치기 때문입니다.

# 인트로
무작위로 하이퍼파라미터를 찾는 것이 더 효율적인 탐색이라는 것을 배웠습니다.            
하지만 무작위라는 것이 가능한 값들 중 공평하게 뽑는 것이라고 할 수는 없습니다.          
대신 적절한 척도를 정하는 것이 더욱 중요합니다.              
이 글에서는 어떻게 척도를 정하는지 알아보겠습니다           

# 합리적으로 파라미터를 고르는 법
![image](https://user-images.githubusercontent.com/50114210/65826185-67d0a700-e2bb-11e9-988a-bb11f8b557a9.png)         
어떤 레이어 l에 대해서 은닉 유닛의 수 n^l을 정한다고 합시다.          
그리고 값의 범위로 50부터 100을 생각해보죠           
이런 경우 50부터 100까지의 수직선에서 무작위하게 값들을 고른다고 합시다.             
하이퍼파라미터를 고르는 꽤 합리적인 방법이지요.            
또는 신경망에서 레이어의 숫자 L을 정한다고 했을 때           
층의 숫자가 2에서 4 사이라고 생각할 수 있겠죠.           
2에서 4까지의 숫자를 선택할 때 무작위하게 뽑는 것은 물론이거니와            
격자점을 사용해도 문제가 없습니다.          
이 예시들은 가능한 값 중 무작위하게 뽑는 것이 합리적인 경우들입니다.           
하지만 모든 하이퍼파라미터가 다 이렇지는 않아요.              

#
![image](https://user-images.githubusercontent.com/50114210/65826198-8cc51a00-e2bb-11e9-8bc8-b8bf47584232.png)         
다른 예시들을 살펴봅시다. 학습률 α를 탐색하는데           
범위로 0.0001부터 1까지를 생각하고 있다고 합시다.           
0.0001에서 1까지의 수직선 상에서 균일하게 무작위로 값을 고르겠죠.            
여기서 약 90%의 샘플이 0.1과 1 사이에 있을 겁니다.           
즉 90%의 자원을 0.1과 1 사이를 탐색하는 데 쓰고         
단 10%만을 0.0001과 0.1 사이를 탐색하는 데 쓰는 것이죠.             
비합리적이지 않나요? 대신 선형 척도 대신 로그 척도에서             
하이퍼파라미터를 찾는 것이 더 합리적입니다.            
수직선 위에 0.0001부터 0.001, 0.01까지 값들이 있겠죠?            
0.1과 1도 있을 테고요. 이런 로그 척도에서            
균일하게 무작위로 값을 뽑는 겁니다.           
그러면 0.0001과 0.001 사이 0.001과 0.01 사이를 탐색할 때             
더 많은 자원을 쓸 수 있는 것이지요.          

# 구현
![image](https://user-images.githubusercontent.com/50114210/65826206-b0886000-e2bb-11e9-86b0-4382e04f2182.png)               
파이썬에서는 어떻게 구현할 수 있을까요?          
r = -4 * np.random.rand()를 쓰고요. 그러면 무작위로 선택된 α 값은 10^r이 되겠죠.               
이 첫 번째 줄에서 r은 -4와 0 사이의 무작위 값일테고            
α 값은 따라서 10^-4와 10^0 사이 10^-4와 1 사이가 되겠지요.             
더 일반적인 경우를 볼까요? 10^a에서 10^b까지를 로그 척도로 탐색한다면         
이 예시에서는 이 값이 10^a가 되겠죠?          
따라서 a는 10을 밑으로 하는 log를 0.0001에 대해 취하면 얻을 수 있습니다.         
그 결과 a가 -4가 될 테고요. 마찬가지로 오른쪽 값도 10^b가 되겠죠.                
여기서 b는 10이 밑인 log를 1에 취하면 0이라는 것을 알 수 있습니다.              
그리고 어떻게 하죠? r은 a와 b사이서 균일하게 무작위로 뽑히고요.             
이 경우 r은 -4와 0 사이겠죠?          
그리고 무작위의 하이퍼파라미터 α는 10^r이 되겠습니다.             
다시 살펴보면 낮은 값에서 log를 취해서 a를 찾고            
높은 값에서 log를 취해 b를 찾습니다.             
이렇게 10^a에서 10^b까지를 로그 척도로 탐색하는 것이지요.             
r은 a와 b 사이에서 균일하게 무작위로 뽑으면          
하이퍼파라미터가 10^r이 되는 것이지요.            
이렇게 로그 척도에서 샘플링하는 법을 배웠습니다.           

# 다른 예시
![image](https://user-images.githubusercontent.com/50114210/65826219-dada1d80-e2bb-11e9-9da8-911a97846e4c.png)        
또다른 예시는 지수가중평균을 계산할 때        
사용되는 하이퍼파라미터 β에 관한 것인데요.            
β를 0.9와 0.999 사이에서 찾는다고 합시다.         
이 범위를 탐색하는 것이지요 0.9의 경우에는 지수가중평균이       
최근 10일의 평균 기온처럼 마지막 10개 값의 평균과 비슷하고             
0.999의 경우에는 마지막 1000개 값의 평균과 비슷했던 것 기억하시나요?     

# 올바른 탐색 방법
![image](https://user-images.githubusercontent.com/50114210/65826241-3ad0c400-e2bc-11e9-84c3-32b23530020f.png)            
방금 전에서 봤던 것처럼 만약 0.9와 0.999 사이를 탐색한다면          
0.9와 0.999 사이를 균일하게 무작위 탐색하는 것은 합리적이지 않습니다.          
더 나은 방법은 1-β에 대해서 값을 탐색하는 것이지요.           
그러면 0.1부터 0.001이 되겠죠?       
그러면 β를 0.1에서 0.01을 거쳐 0.001사이에서 탐색하는 겁니다.          
지난 슬라이드에서 봤던 방법을 써보자면 이건 10^-1이고, 이건 10^-3입니다.         
이전 슬라이드에서는 작은 값이 왼쪽 큰 값이 오른쪽에 있었지만 여기서는 반대입니다.         
큰 값이 왼쪽, 작은 값이 오른쪽에 있죠 즉 여기서 해야 할 일은             
-3과 -1 사이에서 균일하게 무작위로 값을 뽑는 겁니다.          
이제 1-β를 10^r로 생각하면 되니 β가 1-10^r이 되겠죠.          
이렇게 적절한 척도 위에서 무작위로 하이퍼파라미터 샘플을 추출했습니다.            
이 방법을 이용하면 0.9부터 0.99를 탐색할 때와        
0.99부터 0.999를 탐색할 때 동일한 양의 자원을 사용할 수 있습니다.            

# 수학적인 의미
![image](https://user-images.githubusercontent.com/50114210/65826245-55a33880-e2bc-11e9-8ad7-614ff2fd3bd5.png)          
이 쯤 되면 왜 이 방법이 필요한지 수학적 증명이 궁금할텐데요.        
왜 선형 척도에서 샘플을 뽑는 것은 안 좋을까요?       
만약 β가 1에 가깝다면 β가 아주 조금만 바뀌어도 결과가 아주 많이 바뀌게 됩니다.         
예를 들어 β가 0.9에서 0.9005로 바뀌었다면 결과에 거의 영향을 주지 않습니다.            
하지만 β가 0.999에서 0.9995로 바뀌었다면 알고리즘의 결과에 큰 영향을 줄 겁니다.           
이 경우는 대략 10개의 값을 평균내는 것이지만        
여기에서는 마지막 1000개 값의 지수가중평균을 내는 것에서        
마지막 2000개 값의 평균을 내는 것으로 바뀌었으니까요.          
왜냐하면 1/(1-β)라는 식이 β가 1에 가까워질수록 작은 변화에도        
민감하게 반응하기 때문입니다.            
따라서 β가 1보다 가까운 곳에서 더 조밀하게 샘플을 뽑습니다.               
반대로 1-β는 0이 가까운 곳이 되겠지요.             
따라서 가능한 결과 공간을 탐색할 때 더 효율적으로 샘플을 추출할 수 있는 것입니다.                

# 아웃트로
이 영상을 통해 하이퍼파라미터 샘플을 고를 때 적절한 척도를 고를 수 있게 되기를 바랍니다.        
만약 하이퍼파라미터를 고를 때 적절한 척도를 사용하지 않더라도         
크게 걱정할 필요는 없습니다.           
다른 척도가 우선하는 상황에서 균일한 척도에서 샘플링을 하더라도             
정밀화 접근을 사용하면  괜찮은 결과를 얻을 수 있을 테니까요.            
그래서 반복할수록 더 유의미한 하이퍼파라미터 범위를 탐색하게 되는 것이죠.            
