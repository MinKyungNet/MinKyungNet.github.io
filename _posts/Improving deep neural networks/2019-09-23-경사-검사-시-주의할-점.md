---
layout: post
title: "경사 검사 시 주의할 점"
tags: [Gradient Checking]
categories: [Improving deep neural networks]
---

# 학습 목표
경사 검사에 대해서 알 수 있다

# 핵심 키워드
경사 검사(Gradient checking)

# 학습 내용
* 속도가 굉장히 느리기 때문에 훈련시에는 절대 사용하지 않고 디버깅할 때만 사용합니다.
* 알고리즘이 경사 검사에 실패 했다면, 어느 원소 부분에서 실패했는지 찾아봅니다. 특정 부분에서 계속 실패했다면, 그 경사가 계산된 층에서 문제가 생긴것을 확인할 수 있습니다.
* d세타는 세타에 대응하는 J의 정규화 항도 포함하기 때문에 경사 검사 계산시 같이 포함해야 합니다.
* 드롭아웃에서는 무작위로 노드를 삭제하기 때문에 적용하기 쉽지 않습니다. 따라서 통상은 드롭아웃을 끄고 알고리즘이 최소한 드롭아웃 없이 맞는지 확인하고, 다시 드롭아웃을 켭니다.
* 마지막으로 거의 일어나지 않지만 가끔 무작위 초기화를 해도 초기에 경사 검사가 잘 되는 경우입니다. 이 때는 훈련을 조금 시킨 다음에 경사 검사를 다시 해보는 방법이 있습니다.

# 인트로
지난 글에서 경사 검사를 배웠습니다. 이 비디오에서는 신경망에서 이것을 구현하기 위한 실질적인 방법과 팁을 공유하겠습니다.  

# 디버깅에서만 사용   
![image](https://user-images.githubusercontent.com/50114210/65397537-d0b3ad00-ddeb-11e9-9353-88ea1c7263ac.png)     
첫 번째로 훈련에서 경사 검사를 사용하지 말고 디버깅을 위해서만 사용하세요.    
모든 i의 값에 대한 d세타approx[i]를 계산하는 것은 매우 느립니다.    
따라서 경사 검사를 구현하기 위해 d세타를 계산하는 역전파를 이용해 도함수를 계산합니다.    
디버깅할 때만 이 값을 계산하고 d세타에 가까워지게 합니다.    
이 과정이 끝나면 경사 검사를 끄고 모든 반복마다 실행되지 않도록 합니다. 너무 느려질 수 있습니다.    

# 경사 검사를 실패한다면?
![image](https://user-images.githubusercontent.com/50114210/65397564-0fe1fe00-ddec-11e9-978e-abe3009f47c3.png)     
만약 경사 검사의 알고리즘이 실패한다면 개별적인 컴포넌트를 확인해 버그를 확인해보세요.    
제가 의미하는 것은 d세타pprox가 d세타에서 매우 먼 경우 서로 다른 i에 대하여         
어떤 d세타approx[i]의 값이 d세타[i]의 값과 매우 다른지 확인할 것입니다.    
예를 들어 어떤 층에서 세타나 d세타의 값이 대응되는 db[i]와 매우 짧지만,     
대응되는 dw[i]와는 매우 가까운 경우를 살펴봅시다.    
세타의 서로 다른 컴포넌트는 b와 w의 다른 컴포넌트에 대응됩니다.   
이 경우에는 db를 어떻게 계산하느냐에 따라서 버그가 발생할 것입니다. 매개변수 b에 대응하는 도함수입니다.        
비슷한 방식으로 d세타approx의 값이 d세타의 값가 매우 멀고 모든 컴포넌트가 dw혹은 특정한 층에서 dw에서 온 것을 발견한다면    
이를 통해 버그의 위치를 알아내는데 도움을 받을 수 있을 것입니다.       
항상 버그를 바로 찾을 수 있게 하는 것은 아니지만 어디서 버그를 추적할 수 있을지에 대한 약간의 추측을 제공합니다.    

# 정규화항
![image](https://user-images.githubusercontent.com/50114210/65397573-20927400-ddec-11e9-8cd7-23a33c338acf.png)       
다음으로 경사 검사를 할 때 사용하는 정규화 항이 기억나시나요?    
d세타는 세타에 대응하는 J의 경사입니다. 정규화항을 포함합니다.    

# 드롭아웃
![image](https://user-images.githubusercontent.com/50114210/65397574-2a1bdc00-ddec-11e9-98b0-f55b333b83ce.png)        
다음으로 경사 검사는 드롭아웃에서는 작동하지 않습니다.   
모든 반복마다 드롭아웃은 은닉 유닛의 서로 다른 부분집합을 무작위로 삭제하기 때문에    
드롭아웃이 경사 하강법을 시행하는 비용함수 J를 계산하는 쉬운 방법이 없습니다.      
삭제될 수 있는 기하급수적으로 큰 노드의 부분집합으로 정의되기 때문에 비용함수 J를 계산하는 것이 매우 어렵습니다.    
드롭아웃을 사용하면 매번 다른 부분집합의 노드를 무작위적으로 삭제하게 됩니다.    
따라서 드롭아웃을 이용한 계산을 이중으로 확인하기 위해 경사 검사를 사용하기는 어렵습니다.    
따라서 저는 주로 드롭아웃 없이 경사 검사를 구현합니다.   
드롭아웃의 keep_prop을 1.0으로 설정하고 드롭아웃을 켜서 제 드롭아웃 구현이 맞기를 바랍니다.      
삭제된 노드의 패턴을 수정하거나 삭제된 유닛의 패턴이 맞는지 경사 검사를 확인하는 등 다른 방법도 있습니다.    
그러나 저는 실제로 이 방법들을 사용하지 않습니다.   
제가 추천하는 방법은 드롭아웃을 끄고 알고리즘이 최소한 드롭아웃 없이 맞는지 이중 검사하기 위해     
경사 검사를 사용하고 드롭아웃을 켜는 것입니다.    

# 무작위로 초기화 후에 검사
![image](https://user-images.githubusercontent.com/50114210/65397579-330cad80-ddec-11e9-9d59-c699c8b1daaa.png)        
마지막으로 가끔 일어나는 불가능하지 않은 일입니다.    
무작위적 초기화에서 w와 b가 0에 가까울 떄 경사 하강법의 구현이 맞게 된 경우입니다.    
그러나 경사 하강법을 실행하면 w와 b는 점점 커집니다.    
아마 역전파의 구현이 w와 b가 0에 가까울 때만 맞는 것일 수 있습니다.   
그러나 w와 b가 커지면 그 값은 더 부정확해집니다.    
따라서 자주 사용하지는 앟지만 할 수 있는 방법은 무작위적인 초기화에서 경사 검사를 실행하는 것입니다.    
그리고 네트워크를 잠시 동안 훈련해서 w와 b가 0에서 멀어질 수 있는 시간을 줍니다.    
작은 무작위적 초기화 값에서 말이죠.     
그리고 일정 수의 반복을 훈련한 뒤에 경사 검사를 한 번 더 실행시킵니다.  
