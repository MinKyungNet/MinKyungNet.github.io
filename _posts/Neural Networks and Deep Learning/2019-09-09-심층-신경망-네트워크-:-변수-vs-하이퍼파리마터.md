---
layout: post
title: "심층 신경망 네트워크 : 변수 vs 하이퍼파라미터"
tags: [Parameter, Hyperparameters]
categories: [Neural Networks and Deep Learning]
---

# 학습 목표
변수와 하이퍼파라미터를 구별 할 수 있다.

# 핵심 키워드
* 변수(Parameter)
* 하이퍼파라미터(Hyperparameters)

# 학습 내용
* 변수란 신경망에서 학습 가능한 W와 b를 뜻합니다.
* 하이퍼파라미터는 다양하게 있는데, 아래와 같습니다.
1. 학습률(learning rate, 알파)
2. 반복횟수(numbers of iteration)
3. 은닉층의 갯수(numbers of hidden layer, L)
4. 은닉유닛의 갯수(numbers of hidden units)
5. 활성화 함수의 선택(choice of activation function)
6. 모멘텀항(momentum term)
7. 미니배치 크기(mini batch size)
* 매개변수인 하이퍼파라미터를 결정하므로서 최종 모델의 변수를 통제할 수 있습니다.
* 하이퍼파라미터는 결정 된것이 없으며, 여러번의 시도를 통해 적합한 하이퍼파라미터를 찾아야합니다.

# 인트로
효과적으로 심층 신경망을 발전시키기 위해서는 매개변수뿐만 아니라 하이퍼파라미터도 잘 구성해야 합니다.     
하이퍼파라미터가 무엇인지 살펴봅시다.

# 변수와 하이퍼파라미터

![image](https://user-images.githubusercontent.com/50114210/64492104-58a59d00-d2ab-11e9-93f1-20356c4d2173.png)    
여러분 모델의 변수는 W와 b입니다.     
### 변수
![image](https://user-images.githubusercontent.com/50114210/64492109-6e1ac700-d2ab-11e9-8dbf-839e2e893a01.png)    
그리고 학습 알고리즘에 알려줘야 할 것이 있습니다.    
이를테면 학습률을 설정해야 매개변수가 어떻게 진전될지 결정됩니다.    
수행하는 경사 하강법의 반복횟수도 하이퍼파라미터가 될 수 있습니다.   
학습 알고리즘에서 설정해야할 다른 숫자들도 있습니다.    
은닉층의 개수, 은닉 유닛의 개수, 활성화 함수의 선택 등도 선택해야합니다.    
따라서 이 모든 것은 학습 알고리즘에 알려줘야 하는 것들입니다.   
따라서 이 매개변수들은 궁극적으로 매개변수 W와 b를 통제합니다.    
따라서 아래의 매개변수를 하이퍼파라미터라고 부릅니다.   
### 하이퍼파라미터
![image](https://user-images.githubusercontent.com/50114210/64492117-7d017980-d2ab-11e9-9d02-6197e3b48bed.png)    
사실 딥러닝은 매우 다양한 하이퍼파라미터를 가지고 있습니다.   
모멘텀 항, 미니배치 크기, 다양한 형태의 정규화 매개변수 등이 있을 것입니다.   
초기 머신러닝의 시대와 반대로 딥러닝은 아주 많은 하이퍼파라미터를 가지고 있습니다.   
학습률을 매개변수가 아닌 하이퍼파라미터라고 부르겠습니다.   
이렇게 많은 하이퍼파라미터가 없었던 머신러닝의 초기 시대에는 대부분 사람들이 학습률을 매개변수라고 불렀습니다.    
기술적으로 학습률은 매개변수가 맞긴합니다. 그러나 정확히는 진짜 매개변수를 결정하는 매개변수입니다.   
따라서 학습률, 반복 회수등을 하이퍼파라미터라고 부르겠습니다.    

# 경험적으로 결정하는 하이퍼파라미터

![image](https://user-images.githubusercontent.com/50114210/64492131-a28e8300-d2ab-11e9-9b4d-59752dae0bdf.png)    
여러분의 애플리케이션에 맞게 심층망을 학습시킬 때 시도할 필요가 있는 하이퍼파라미터에 가능한 설정들이 많다는 것을 알게 될 것입니다.    
오늘날 딥러닝을 적용하는 것은 매우 경험적인 과정입니다.    
예를 들어 학습률에 가장 적합한 아이디어가 있을 때 학습률을 0.01을 두고 시도해 볼 수 있습니다.   
그럼 이것을 구현하고 시도해서 결과에 기반해 어떻게 작동하는지 보면 마음을 바꿔 학습률을 0.05로 바꿀 수도 있습니다.    
어떤 값의 학습률을 사용해야 할지 확실하지 않다면 학습률에 하나의 값을 넣어보고 비용함수 J가 어떻게 내려가는지를 확인합니다.    
그렇게 학습률에 다양한 값을 시도해보고 꽤 빠르게 학습되고 낮은 비용함수로 수렴하는 값을 선택합니다.    


![image](https://user-images.githubusercontent.com/50114210/64492136-ba660700-d2ab-11e9-9825-9a652ac5efa5.png)     
하이퍼파라미터의 종류는 다양합니다. 그렇지만 하이퍼파라미터의 가장 적합한 값을 정확히 미리 아는 것이 매우 어렵습니다.    
따라서 자주 사용하는 방법은 다양한 값을 시도하고 몇가지 값들을 시도합니다.   
예를 들어 은닉 유닛에 5개의 은닉층을 시도합니다. 그것을 구현하고 작동하는지 확인하는 과정을 반복합니다.   
이 슬라이드의 제목은 '딥러닝을 적용하는 것은 매우 경험적인 과정이다.'입니다.    
경험저인 과정이라는 것은 많은 것을 시도하고 작동되는지를 확인한다는 것입니다.    

제가 본 또 다른 효과는 오늘날의 딥러닝은 컴퓨터 비전부터 음성 인식, 자연어 처리까지 아주 다양한 범위의 문제에 적용된다는 것입니다.    
구조화된 데이터 애플리케이션에 많이 적용됩니다. 온라인 광고, 웹 검색, 혹은 제품 추천처럼요.    
또한 제가 느낀 것은 어떤 전공의 연구원이든 서로 다른 것을 시도하면 하이퍼파라미터에 대한 직관을 이어가고 어떤 경우는 그렇지 않았습니다.    
따라서 특히 새로운 문제를 시작하는 사람들에게 제가 하는 조언은 값의 범위를 시도하고 무엇이 작동하는지 확인하라는 것입니다.
도 다른 느낀점은 오랫동안 하나의 애플리케이션에서 작업하고 있는 경우에도 예를 들어 온라인 광고의 경우 문제에 대한 진전은 계속됩니다.   
학습률과 은닉 유닛의 개수 등에 관한 가장 적합한 값도 바뀔 가능성이 큽니다.    
하이퍼파라미터의 가장 정확한 값으로 시스템을 설정해 놓았어도 지금으로부터 1년 뒤에는 그 값이 바뀔 수 있습니다.
CPU나 GPU의 종류같은 컴퓨팅 기반 시설이 바뀔 수 있으니까요.    
그러나 경험적인 규칙을 말씀드리자면 하나의 문제에 대해 장기간 다루는 경우에     
몇 달마다 하이퍼파라미터에 몇 가지 값을 시도하고 더 좋은 값이 있는지 이중으로 확인해보세요.     
그럼 여러분의 문제에 가장 적합한 하이퍼파라미터를 찾는 직관을 천천히 얻게 될 것입니다.    
이 하이퍼파라미터에 대해 모든 값을 시도해봐야 한다는 것이 딥러닝의 만족스럽지 않은 부분이라는 것을 압니다만, 이것도 한 시대일 뿐입니다.     
딥러닝 연구는 계속 발전하고 있고 시간이 흐르면서 가장 적합한 하이퍼파라미터를 찾는데 더 나은 지침을 줄 수 있을 것입니다.
그러나 CPU, GPU, 네트워크, 데이터가 모두 바뀌고 있기 대문에 어떤 경우에는 지침이 적용되지 않는 경우가 있을 수 있습니다.    
그 경우에는 다양한 값을 시도하고 평가해야 합니다. 그리고 해당 문제에 작동하는 값을 선택해야합니다.    






