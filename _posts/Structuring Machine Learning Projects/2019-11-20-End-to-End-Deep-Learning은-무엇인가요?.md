---
layout: post
title: "End to End Deep Learning은 무엇인가요?"
tags: [End to End Deep Learning, Pipeline]
categories: [Structuring Machine Learning Projects]
---

# 학습 목표
end to end 딥러닝을 학습한다.

<br>

# 핵심 키워드
* end to end 딥러닝
* 파이프라인(pipeline)

<br>

# 학습 내용
* end to end 딥러닝은 자료처리 시스템 / 학습 시스템에서 여러 단계의 필요한 처리과정을 한번에 처리합니다. 즉, 데이터만 입력하고 원하는 목적을 학습시키는 것입니다.
* 이는 기존의 처리 파이프라인 중 일부를 대체할 수도 있습니다. 다만, end to end 딥러닝을 사용하기 위해서는 엄청나게 많은 양의 데이터가 필요합니다.
* end to end 딥러닝이 만능은 아닙니다. 단계를 나눠서 학습 시키는 것이 효율적일 때도 있습니다. 효율적인 이유는 아래와 같습니다.
  - 복잡한 문제를 분리하여 각각의 간단한 문제로 바꿉니다.
  - 데이터의 정보가 각각의 작업에 더 적합되게 사용됩니다.
* 따라서, 순수 end to end 딥러닝 보다는 문제를 쪼개서 해결하는 것이 좋습니다.

<br>

# 인트로
최근 딥러닝의 분야에 있었던 가장 큰 발전은 end-to-end 딥러닝입니다.           
그렇다면 end-to-end 딥러닝이란 무엇일까요?         
자료 처리 시스템이나 학습 시스템에는 여러 단계의 처리과정을 요구하는 경우가 있는데           
end-to-end 딥러닝은 그 여러 단계들을 받아서 재배치합니다. 단 하나의 신경망을 이용해서 말이죠.               
예시를 한 번 살펴봅시다.          

<br>

# 전통적인 알고리즘
![image](https://user-images.githubusercontent.com/50114210/69194995-e9331000-0b6d-11ea-9832-c7eae5039c30.png)           
음성인식을 예로 들어봅시다. 입력값 x 를 녹음 파일로 두고 출력값 y 를 녹음 파일의 대본이라고 합시다.          
출력값 y 를 녹음 파일의 대본이라고 합시다. 전통적으로 음성 인식은 여러 개의 처리 단계를 요구합니다.          
먼저는 녹음 파일의 특징들을 추출해내고 MFCC 에 대해서             
들어본 사람들은 알테지만 녹음 파일의 특징을 추출해내는 알고리즘입니다.      
간단한 특징들을 추출해낸 뒤 머신 러닝 알고리즘을 이용해 녹음 파일의 음소를 알아내는 것이죠.            
음소란 소리의 기본 단위인데 cat 이라는 단어는 세 개의 소리로 되어있죠.      
이러한 음소들을 찾아낸 뒤 묶어서 하나의 단어를 만듭니다.          
그리고 그 단어들을 조합해서 녹음 파일의 대본을 만드는 것이죠.        

<br>

# end to end 딥러닝
![image](https://user-images.githubusercontent.com/50114210/69195005-f6e89580-0b6d-11ea-8eb0-cbe7ebe88819.png)         
이렇게 여러 단계를 거쳐야 하는 반면에 end-to-end 딥러닝은                      
하나의 네트워크를 훈련시켜서 녹음 파일을 받고 한 번에 대본을 얻게 할 수 있죠.                 
인공지능의 흥미로운 사회학적 효과는 딥러닝이 점점 발전하면서 파이프라인의 한 단계를 수 년 동안 연구해오던 사람들은                 
음성인식 뿐만 아니라 다른 여러 분야도 물론 컴퓨터 비전이나 많은 다른 분야에 있는 사람들은               
많은 시간을 쏟고 논문도 발표했고 커리어의 많은 부분을 특징이나 파이프 라인의 일부분을 엔지니어링하는데 투자했을 겁니다.          
end-to-end 딥러닝이 그저 많은 훈련 집합을 통해서 여러 중간 단계를 생략하고 x 를 y 로 이끄는 법을 학습했을 때           
특정 분야에 종사하는 많은 사람들에게 타격을 줬고 인공지능 시스템을 구축하는 새로운 방식으로 인해서                  
중간 단계의 연구들이 한 순간에 구식이 되어버린 것입니다.         

<br>

# end to end 딥러닝의 제한 사항
![image](https://user-images.githubusercontent.com/50114210/69195023-01a32a80-0b6e-11ea-8fef-769de292bf81.png)       
end-to-end 딥러닝에서 장애물이 되는 것은 사전에 많은 정보가 필요하다는 것입니다.           
3000 시간 정도 분량의 자료를 훈련시키려 할 때 공간 지각 시스템을 구축하기 위해서        
기존의 온전한 파이프 라인 시스템은 잘 작동할 것입니다.           
그러나 만약 10,000 시간 분량의 자료들이나 혹은 100,000 시간 이상의 자료들이 존재한다면          
end-to-end 식 접근이 훨씬 잘 작동하게 됩니다.            
작은 데이터 집합일수록 기존의 처리 방식이 잘 작동하는 것이죠.        
많은 양의 데이터가 있어야지만 end-to-end 접근이 빛을 발하게 됩니다.         
만약 중간 정도 분량의 데이터가 있다면 중간급의 접근 방식으로            
여러 특징들을 생략하고 신경망의 음소를 학습한 뒤 또 여러 과정이 있을 수 있습니다.         
end-to-end 학습법에 가깝지만 완전하지는 않죠.       

# 얼굴 인식 개찰구 예시
![image](https://user-images.githubusercontent.com/50114210/69195428-f4d30680-0b6e-11ea-9228-e9b29d3abaaa.png)          
이 사진은 얼굴 인식 개찰구로 Baidu 의 Yunci Lin 이 개발한 것으로 여기 이 카메라가 접근하는 사람을 보고           
그 사람을 인식해서 자동으로 지나갈 수 있게 열리게 하는 것입니다.          
RFID 를 사용할 필요 없이 출입할 수 있고 중국의 많은 회사에서 사용되고 있습니다.           
개찰구로 가서 얼굴을 인식만 하면 들어갈 수 있죠. RFID 배지 없이 말입니다.          
어떻게 이런 시스템을 구축할까요?         

<br>

# end to end 시스템
![image](https://user-images.githubusercontent.com/50114210/69195456-103e1180-0b6f-11ea-9c20-f3641474c6d1.png)              
한 가지 할 수 있는 것은 카메라가 캡쳐한 이미지를 보는 것입니다.          
그림 솜씨가 좋지는 못하지만 카메라의 이미지라고 합시다.        
그래서 누군가가 개찰구로 접근하고 있고 이것이 그 입력 이미지 x가 되겠죠.       
여기서 할 수 있는 것은 학습하는 함수를 이미지 x 에서 바로 개인의 신분인 y 를 알아보게 하는 것입니다.            
하지만 이것이 최고의 접근법은 아니었죠.       
여기 있었던 한 가지 문제는 개찰구로 접근하는 사람이 한 방향으로만 오지는 않는다는 것입니다.          
여기 이 초록색의 위치나 파란색의 위치에 있을 수도 있고 카메라와 가까워서 이미지가 더  커 보일 수 있고             
이미 카메라 가까이 접근해서 얼굴이 훨씬 커보일 수 있습니다.       

<br>

# 문제를 단순화, 많은 학습 자료
![image](https://user-images.githubusercontent.com/50114210/69195520-3499ee00-0b6f-11ea-8c06-259be395d0a9.png)          
그래서 이 개찰구를 만들 때 이미지를 그대로 가져가서 신경망에 그대로 넣어  그 사람의 신분을 알아내는 것이 아니라              
오늘 날의 최고의 방법은 여러 단계에 걸친 접근 방식으로 먼저 하나의 소프트웨어로 사람의 얼굴을 인식합니다.              
그래서 처음으로는 인식기를 통해 얼굴의 위치를 찾습니다.        
얼굴을 인식한 뒤에는 그 부분을 확대해서 잘라낸 뒤 정중앙에 위치하게 합니다.            
여기 빨간색으로 그린 것이 그것을 나타내는 것이고 이것이 신경망으로 들어가 신분을 추측하거나 학습하는 것이죠.          
연구에 의하면 이 모든 것을 한 단계로 진행하는 것보다 두 개의 간단한 단계로 나누는 것이 낫습니다.                     
첫 번째는 얼굴이 어디있는지 찾는 것이고 두 번째가 얼굴을 보고 누구인지 인식하는 것이죠.                   
이 방법으로 두 개의 알고리즘이 더 간단한 작업을 각각 처리하면서 더 나은 성능을 가지게 되는 것입니다.                      
만약 이 두 번째 과정이 어떻게 이루어지는지 알고싶다면 사실 제가 설명을 간단하게 하기는 했지만               
두 번째 단계는 신경망을 훈련시킬 때 두 개의 이미지를 받고            
신경망은 두 개의 이미지를 보고 둘이 같은 사람인지 아닌지 알아내는 것입니다.       
만약 10,000 명의 사원의 ID 가 있을 때 이 이미지를 빠르게 읽고 10,000 명의 ID 와 비교하면서               
이 빨간색 그림이 10,000명 중 한 명의 직원인지 알아보고                  
시설 혹은 건물에 들여보낼지 아닐지 판단하거나 개찰구라면 작업장에 들어갈 수 있게 하는 것이죠.                  

<br>

# end to end 접근보다 성능이 좋았던 이유
왜 두 단계의 접근이 더 좋은 성능을 보여줄까요? 거기에는 두 가지 이유가 있습니다.              
**첫 번째로는 각각의 문제가 더 간단해졌기 때문**이고 둘째로는** 많은 자료들이 각각의 작업에 적용되기 때문**입니다.        
얼굴 인식의 첫 번째 작업에서 많은 자료를 얻을 수 있습니다.                 
이미지를 보고 얼굴이 어디있는지 알아내는 작업 말이죠.         
(x, y) 의 형태로 많은 데이터가 존재할텐데 x 는 사진이고 y 는 얼굴의 위치가 되겠죠.         
그렇게 첫 번째 작업을 수행할 신경망을 구축할 수 있습니다.     
그리고 두 번째 작업에도 별개의 많은 자료들이 있습니다.         
오늘날의 선진 기업들이 수십만개의 얼굴 사진을 가지고 있다고 해봅시다.          
빨간색 이미지나 그 아래처럼 잘라낸 이미지들을 뛰어난 얼굴 인식 기술 팀들은           
적어도 수 백만 개의 이미지로 두 이미지를 살펴보고 신분을 알아내거나 동일 인물인지 알아낼 수 있는 것이죠.           
두 번째 작업에도 많은 자료가 있습니다.       
반면에 만약 모든 것들을 한 번에 학습하려 한다면 (x, y) 형태의 자료가 훨씬 적을 것입니다.            
x 가 개찰구에서 얻을 이미지고 y 가 사람의 신분일 때 말이죠.        
end-to-end 학습 문제를 해결하기에는 정보가 부족하지만 두 단계로 나뉜 문제를 해결하기에는 충분하기에        
실전에서는 문제를 여러 개로 쪼개는 것이 순수한 end-to-end 딥러닝보다 더 나은 성능을 보여주는 것입니다.         
end-to-end 방식의 접근을 위한 정보가 충분하다고 해도 더 나은 성능을 보여주지 않을 수 있습니다.         
하지만 이것도 실전에서 가장 효과적인 방식이 아니죠.       

<br>

# 기계 번역 예시
![image](https://user-images.githubusercontent.com/50114210/69195692-c1dd4280-0b6f-11ea-833c-8c9972e244e0.png)         
다른 예를 살펴봅시다. 기계 번역을 예로 들어봅시다.       
전통적으로 기계 번역 시스템도 복잡한 처리방식을 가져서 먼저 영어로 말하고          
문자를 분석해서 문자의 특성들을 추출해내고 출력까지 수많은 과정을 거쳐서 영어를 불어로 번역하는 것이죠.           
기계 번역에는 많은 (영어, 불어) 쌍이 존재하고 end-to-end 딥러닝 은 기계 번역에서 꽤나 잘 작동합니다.       
왜냐하면 요즘에는 많은 양의 x, y 쌍을 얻을 수 있기 때문이죠.          
이 예제에서는 영어를 불어로 번역하는 것인데 여기서는 end-to-end 딥러닝이 잘 작동합니다.        

<br>

# 손 엑스레이 사진으로 아이의 나이 추정 예시
![image](https://user-images.githubusercontent.com/50114210/69195706-c99ce700-0b6f-11ea-9da9-1fb69a8c0553.png)            
마지막 예시로는 한 아이의 손을 엑스선로 보고 아이의 나이를 추측한다고 합시다.          
소아과 의사들은 이것을 이용해서 아이가 정상적으로 성장 중인지 아닌지 판단하고는 합니다.          
end-to-end 가 아닌 방식으로는 먼저 이미지를 받아서 뼈의 마디를 나누어서 인식하게 될 것입니다.           
각각의 뼈마디가 어디에 있을지 찾아보겠죠.           
서로 다른 뼈마디를 찾은 뒤에는 표에서 어린 아이의 평균 뼈마디 길이를 살펴보면 됩니다.         
이렇게 아이의 나이를 측정할 수 있고 실제로 꽤나 효과적입니다.            
반면에 이미지에서 바로 아이의 나이를 측정하려면 그만큼 많은 양의 정보가 필요합니다.          
제가 알기로는 지금 시점에서 효과적인 방법은 아닙니다. 이 작업을 학습하기 위한 정보가 충분하지 않기 때문이죠.          
반면에 이 작업을 두 단계로 나누어 처리하면 첫 번째는 상대적으로 쉬운 작업이라서 많은 양의 정보가 필요하지 않을 것입니다.               
엑스레이에서 뼈마디를 찾기 위해 많은 이미지가 필요하지는 않죠.           
두 번째 단계는 몇몇 아이들의 손 크기 정보를 수집하기만 하면 그렇게 많지 않은 정보로도 이루어낼 수 있을 것입니다.           
그래서 이 다단계의 접근 방식이 매우 유용한 것이죠. 어쩌면 end-to-end 방식보다 더 효과적일 수도 있습니다.            
end-to-end 를 실행할 만큼의 정보가 아직 없을 때는 말이죠. 

<br>

# 아웃트로
end-to-end 학습법은 실제로 아주 잘 작동합니다.       
시스템을 굉장히 많이 단순화할 수 있고 중간 과정을 구축하는데 많은 공을 들이지 않아도 됩니다.           
그러나 만병통치약은 아니죠.         
