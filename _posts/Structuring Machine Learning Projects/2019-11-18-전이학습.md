---
layout: post
title: "전이 학습"
tags: [transfer learning, low-level feature]
categories: [Structuring Machine Learning Projects]
---

# 학습 목표
전이 학습을 배운다

<br>

# 핵심 키워드
* 전이 학습(transfer learning)
* 저레벨 특성(low-level feature)

<br>

# 학습 내용
* 지도학습의 경우, 전이학습의 방법은 기존 학습된 모델에서 마지막 층을 제거한 후, 분류하고자 하는 문제에 적합한 층을 연결시켜주고 학습하게 됩니다.
  - 풀고자 하는 문제의 데이터가 많을 경우, 모든 층을 재훈련합니다.
  - 풀고자 하는 문제의 데이터가 거의 없을 경우, 새로 추가한 마지막 층만 학습하게 합니다.
* 전이학습의 장점은 기존에 학습된 지식을 데이터가 적은 문제에 적용시킬 수 있다느 점입니다. 이미지 같은 경우, 저 레벨의 특성, 즉, 윤곽이나 물체의 일부분을 탐지하는 지식이 방사선의학에 적용할 수 있습니다.
* 전이학습으 아래의 상황에서 많이 쓰입니다.
  - 전이 가능한 문제의 데이터는 많은데 전이하려고 하는 문제의 데이터가 정말 적을 때
  - 입력 데이터가 같을 고, 저레벨 특성이 문제를 해결하는데 도움이 될 때
  
<br>

# 인트로
딥러닝에서 가장 강력한 아이디어 중 하나는 지식을 이용할 수 있다는 것인데요.          
신경망이 한 작업에 대해 학습을 이미 한 경우 그 지식을 다른 종류의 작업에 이용하는 것을 말합니다.          

# 전이 학습
![image](https://user-images.githubusercontent.com/50114210/69051143-d671eb80-0a46-11ea-98c9-bbdf87352e34.png)            
예를 들어 신경망이 고양이와 같은 사물을 인식하도록 학습되었다면            
이 지식의 일부부을 다른 작업을 하는데 사용할 수 있습니다.      
x-ray 이미지를 읽어들이는 작업에 말이죠. 그리고 이것을 전이 학습이라고 부릅니다.         
이미지 인식에 대해서 신경망을 학습시켰다고 해보겠습니다.          
먼저 이 신경망을 (x, y) 쌍에 대해서 훈련을 시키게 될 것입니다.             
x는 이미지를 의미하고 y는 이미지 안의 어떤 물체를 의미합니다.          
고양이, 개, 새와 같은 것들이죠 이제 이 신경망을 사용하여 전이시키고자 합니다.           
다른 작업에 대해 학습하도록 하는 것이죠. x-ray 사진을 판단하는 방사선의학 같은 것에 사용합니다.         
먼저 신경망의 마지막 출력층을 삭제해버리도록 하겠습니다. 마지막 출력층으로 가는 화살표도 없애도록 하겠습니다.         
그리고 마지막 층에 대해 새롭게 무작위 초기화된 세트를 만듭니다.           
이것은 방사선의학에 대한 새로운 출력이 되는 것이죠.         
이미지 인식 작업을 훈련할 때 훈련의 첫 번째 단계에서 신경망의 모든 일반적 변수를 모든 층에서 훈련시킬 것입니다.          
그리고 여기서 이미지 인식에 대한 예측값이 나오는 것이죠.          
이제 이 훈련된 신경망을 이용해 전이 학습을 진행하기 위해서 새로운 데이터 세트 (x, y)를 교체해야 합니다.         
x는 방사선 이미지를 의미하죠. y는 예측하고자 하는 질병을 의미합니다.          
이제 마지막 층에서 w^[l], b^[l]를 무작위 초기화합니다.         
그리고 새로운 데이터 세트에 대해 신경망을 재훈련 시킵니다.         
그러니까 새로운 방사선 이미지 데이터 세트에 대해서 말이죠 

# 프리 트레이닝과 파인 튜닝
![image](https://user-images.githubusercontent.com/50114210/69051364-6ca61180-0a47-11ea-9495-5178355cd12d.png)            
신경망을 방사선 데이터로 재학습시키는데 두 가지 옵션이 있습니다.        
적은 양의 방사선 이미지 데이터 세트를 사용한다면
마지막 층의 w^[l]과 b^[l]에 대해서만 재훈련하고 다른 변수들은 고정시켜두는 것이 좋습니다.         
만약 충분한 데이터를 가지고 있다면 신경망의 모든 층을 다시 훈련시킬 수도 있습니다.          
경험 법칙에 따라서 작은 데이터 세트에 대해서는 마지막 한 개의 출력층만 재훈련합니다.           
또는 마지막 한두 개의 층만 재훈련시키는 것이죠.        
하지만 많은 데이터가 있는 경우 신경망의 모든 변수를 재훈련합니다.         
신경망의 모든 변수를 재훈련하게 되면 이미지 인식에서의 첫 번째 훈련 단계는 종종 사전 훈련이라고 불립니다.           
이미지 인식 데이터를 이용해 신경망을 사전 훈련하는 것이기 때문이죠.        
그리고 이것을 모두 다시 갱신한 후에 방사선 데이터에 대해 훈련하는 것이죠.         
이것을 세부 조정이라고 부릅니다. 딥러닝에서 사전 훈련과 세부 조정에 대해 들어보셨을 텐데요.        
전이 학습에서의 사전 훈련과 세부 조정은 이것을 뜻하는 것입니다.           

# 전이 학습이 잘 되는 이유
이 예시에서는 이미지 인식에서 나온 지식을 이용해 방사선의학에 적용시켰습니다.                 
이것이 유용한 이유는 **낮은 수준의 특성때문인데 윤곽이나 커브를 감지하거나 물체의 일부분을 감지하는 것**들이죠.           
이미지 인식을 매우 큰 데이터터 세트에서 학습하는 것은 학습 알고리즘이 방사선의학에서도 더 잘 작동하는데 도움이 됩니다.          
이미지가 어떻게 생겼는지에 대한 구조를 이해할 수 있기 때문에 이 지식이 유용하게 사용됩니다.         
따라서 이미지 인식에 대해 충분히 학습된 경우라면 각 이미지가 어떤 부분이 다른 것인지 알 수 있습니다.            
그리고 이 선, 점, 커브 또는 물체의 특정한 작은 부분에 대한 지식으로 방사선의학 신경망이 적은 데이터만으로 학습할 수 있다는 것이죠.           

# 음성 인식 예제
![image](https://user-images.githubusercontent.com/50114210/69051412-94957500-0a47-11ea-81b9-067a814e2ea4.png)           
다른 예시를 하나 더 보여드리겠습니다. 음성 인식 시스템을 훈련한다고 해보겠습니다.         
x는 입력되는 음성이고 y는 그것에 대한 원고가 되겠죠.         
음성 인식 시스템을 훈련시켜 원고 내용을 출력하는 것이죠.         
시작 단어 또는 유발 단어 감지 시스템을 만든다고 가정해 보겠습니다.          
기억하고 있듯이 시작 단어 또는 유발 단어는 집에서 음성 제어 장치를 깨우는데 사용합니다.          
'알렉사' 라고 말하는 것이 아마존 에코를 깨우고 '오케이 구글'이라고 말하는 것은 구글 디바이스를 깨우죠.        
그리고 '시리야'라고 말하는 것으로 애플 디바이스를 깨울 수 있습니다.          
또 '니하오 바이두'는 바이두의 디바이스들을 깨웁니다.        
이것들을 하기 위해서 여기서도 신경망의 마지막 층을 없애고 새로운 출력 노드를 만듭니다.           
가끔은 단지 단일 출력을만드는 것이 아니라 신경망에 여러개의 새로운 층을 만들어서          
이 시작 단어 감지를 위해 y값을 예측하게 할 수도 있습니다.      
그리고 얼마나 많은 데이터를 가지고 있는지에 따라서                
신경망의 새로운 층을 다시 훈련시킬 수도 있고 또는 더 많은 층들을 다시 훈련시킬 수도 있습니다.          

# 전이 학습이 잘 되는 경우
그렇다면 어떤 상황에서 전이 학습이 잘 적용될까요?            
**전이 학습은 전이되는 문제의 데이터는 많고 전이하려고 하는 문제의 데이터가 적을 때 잘 적용됩니다.**       
예를 들어 이미지 인식 작업에서 백만 개의 샘플이 있다고 해보겠습니다.         
낮은 수준의 특성에 대해 학습할 수 있는 많은 데이터를 가지고 있는 것이죠.         
또는 신경망의 초기 층에서의 특성들에 대해 학습할 수 있는 것입니다.        
하지만 방사선의학 작업에서는 백 개정도의 샘플만 있다고 하겠습니다.          
이 방사선의학 문제에 대해서는 굉장히 적은 데이터만 가지는 것입니다. 백 개정도의 x-ray 사진이 있는 것이죠.       
따라서 이미지 인식으로 부터 학습한 지식들은 전이되어 방사선의학 작업에 많은 도움이 될 수 있을 겁니다.              
방사선의학에 대한 데이터가 별로 없다고 하더라도 말이죠.      
음성 인식에 대해서는 1만 시간의 음성 데이터로 학습한다고 하면            
이 1만 시간의 데이터로 인간의 음성이 어떤 형식인지 학습할 수 있겠죠. 굉장히 많은 데이터입니다.          
유발 단어 감지 작업에서는 1시간의 데이터만 가지고 있다고 할 때 이것은 변수를 충분히 계산하기엔 적은 데이터입니다.         
따라서 이 경우에는 인간 음성이 어떤 형식인지 또 인간의 음성이 어떻게 구성되는지 이미 많이 학습했기 때문에        
이것이 좋은 시작 단어 감지기를 만드는데 많은 도움이 될 것입니다.             
상대적으로 적은 양의 데이터만 가지고 있다고 하더라도 말이죠. 시작 단어 감지 작업에 필요한 것보다 훨씬 적은 경우이긴 하죠.                 
이 두 가지 경우 모두 많은 데이터를 가진 문제에서 상대적으로 적은 데이터를 가진 문제로 전이시키는 경우입니다.         
전이 학습을 적용할 수 없는 한 가지 경우가 있는데 이것이 반대가 되는 경우입니다.         
만약 이미지 인식에서 백 개의 이미지가 있고 방사선의학에서 백 개 또는 천 개의 이미지가 있다고 해봅시다.           
여기서 방사선의학이 잘 작동하기 위해서 무엇이 필요한지 잘 생각해보아야 합니다.          
개나 고양이 이미지보다는 방사선 이미지가 더 도움이 되겠죠.          
따라서 이 샘플들은 여기의 샘플보다 훨씬 효과가 있습니다. 좋은 방사선의학 시스템을 만들기 위해 필요한 것들이죠.          
따라서 방사선 데이터를 훨씬 많이 가지고 있다면         
고양이, 개, 자동차와 같은 임의의 물체에 대한 이미지들은 그리 도움이 되지 않을 가능성이 높습니다.          
개나 고양이와 같은 이미지 인식 작업에서의 이미지 한 개보다            
x-ray 이미지 한 개가 방사선의학 시스템에 더 효과적이기 때문입니다.          
이 예시에서 전이 학습이 문제가 되는 것은 아니지만 그다지 의미 있는 결과를 얻을 수 없을 것입니다.          
비슷하게 10시간 길이의 데이터로 음성 인식 시스템을 만드는 경우에 50시간 정도의 시작 단어 감지 데이터가 있다고 하면          
이 경우에도 전이 학습을 하더라도 문제가 생기는 것은 아니지만 하지만 의미 있는 결과를 예상하는 건 어려울 것입니다.          

# 전이 학습 요약
요약해보자면 전이 학습이 잘 적용되는 경우는 A라는 작업에서 학습하고          

### 같은 인풋을 가질 때
![image](https://user-images.githubusercontent.com/50114210/69051977-294ca280-0a49-11ea-895c-f0b0dac115dd.png)      
그 지식을 B 작업으로 전이하는 상황에서 A와 B가 같은 입력 x를 가질 때 전이 학습이 적용할 수 있습니다.        
첫 번째 예시에서는 A와 B가 이미지를 입력으로 설정했죠.        
그리고 두 번째 예시에서는 두 작업 모두 음성을 입력으로 했습니다.     
그리고 A가 B보다 더 많은 데이터를 가질 때 잘 적용됩니다.          
이 모든 것은 작업 B에서 좋은 결과를 얻기 위한 것이죠.         

### 전이 학습 시키는 데이터가 훨씬 많아을 때
![image](https://user-images.githubusercontent.com/50114210/69051985-323d7400-0a49-11ea-9148-02600cf4cfff.png)        
B에 대한 데이터는 B 작업에 더 효과적이므로 A에 대한 데이터의 경우  훨씬 많은 데이터가 필요합니다.        
A의 샘플들은 B에 대해서는 B의 샘플에 비해 덜 효과적이기 때문이죠.           

### 낮은 수준의 특성을 학습 시킬 때
![image](https://user-images.githubusercontent.com/50114210/69052016-43868080-0a49-11ea-96c2-bde13f6939d0.png)       
마지막으로 전이 학습은 A의 낮은 수준 특성들이 B를 학습하는데 도움이 되는 경우 잘 적용됩니다.        
앞에서 두 예시에서 이미지 인식을 학습하는 것은 방사선의학에 도움을 주고            
음성 인식의 학습은 시작 단어 감지에 대한 정보를 줍니다.        

# 아웃트로
요약하자면 전이 학습은 작업 B가 적은 데이터를 가질 때 유용하게 사용됩니다.          
예를 들어 방사선의학에서는 좋은 방사선의학 시스템을 만들기 위해 x-ray 이미지를 많이 얻는 것이 어렵습니다.       
따라서 이 경우에 이미지 인식과 같은 다른 작업에서 백만 개의 이미지를 얻을 수 있을 것이고          
그리고 이것으로 부터 낮은 수준 특성을 학습하면 방사선의학 작업에서도 더 좋은 결과를 얻을 수 있습니다.      
이것에 대한 많은 데이터가 없더라도 말이죠.         
전이 학습은 학습 알고리즘의 성능에 상당히 영향을 주는 경우에 전이 학습이 적용될 수 있는 몇 가지 경우를 보았죠.          
작업 A가 B보다 적은 데이터를 가지는 경우 효과를 기대하긴 어렵습니다.      
