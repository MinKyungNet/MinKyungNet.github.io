---
layout: post
title: "최적화 척도 만족시키기"
tags: [Optimizing metric, Satisficing metric]
categories: [Structuring Machine Learning Projects]
---

# 학습 목표
최적의 기준을 세우는 방법을 배운다.

# 핵심 키워드
* 최적화 척도(optimizing metric)
* 조건 척도(satisficing metric)

# 학습 내용
많은 것을 고려해야할 때, 성능을 최대로 높이고 싶은 하나를 최적화 척도로 두고, 조금 덜 중요한 목표는 조건 척도로 설정하여 자동으로 모델 평가를 할 수 있도록 합니다.

# 인트로
여러분이 중요하게 생각하는 모든 것을 하나의 실수 평가 기준으로 합치는 것이 항상 쉬운 일이진 않습니다.        
이런 일들을 하다보니 만족스러운 최적의 기준을 세우는 것이 쓸모가 많더군요.        

# 여러 기준
![image](https://user-images.githubusercontent.com/50114210/68034600-538e2880-fd05-11e9-944c-3c5c25b0f2c2.png)       
여러분이 고양이 분류기의 분류 정확도를 신경쓴다고 합시다.         
이것은 F1 지수 등 정확도를 측정하는 지수입니다.         
그리고 정확도에 더하여 실행 시간도 중요하게 생각한다고 하죠.        
사진을 분류하는 데 걸리는 시간 말이에요.         
분류기 A는 80ms, B는 95ms C는 1,500ms가 걸립니다.         
사진을 분류하는 데 1.5초가 걸리네요.         

# 정확도와 실행 시간의 결합
![image](https://user-images.githubusercontent.com/50114210/68034696-86382100-fd05-11e9-96f0-a0b27be83eda.png)       
여러분인 전체적인 평가 기준에 정확도와 실행 시간을 결합할 수 있습니다.         
전체 비용은 정확도에서 0.5배의 실행 시간을 뺀 값이 될 수 있겠죠.        
하지만 정확도와 실행 시간을 이런 식으로 합치는 것은 다소 인위적입니다.            
이렇게 선형적으로 합치는 게 말이죠.         

# 최적화 척도, 조건 척도
![image](https://user-images.githubusercontent.com/50114210/68034735-9b14b480-fd05-11e9-8b79-3f1b48d8929e.png)     
대신 이렇게 할 수도 있습니다.        
우선 정확도가 최대인 분류기를 선택하되
이미지를 분류하는 데 걸리는 시간인 실행 시간이 100ms보다 작은 것 중에 고르는 거죠.        
여기에서 정확도를 최적화 척도이라고 합니다.         
왜냐하면 최대의 정확도를 원하기 때문이죠.        
실행 시간은 조건 척도라고 합니다.           
어떤 조건만 만족하면 된다는 것이죠.         
100ms보다 작기만 하면 그것보다 좋아도 상관 않겠다는 겁니다.          
또는 그만큼 중요하게 생각을 않는 거죠.       
비록 정확도와 실행 시간을 결합시켰을 때와 비교해서              
트레이드오프가 있지만 이것도 꽤 합리적인 방법입니다.         
이런 경우가 있을 수 있죠.         
사용자가 실행 시간이 100ms보다 낮으면 그렇게 신경쓰지 않는 거죠.          
100ms나 50ms, 또는 그보다 더 빨라도 말입니다.          
최적 척도와 조건 척도를 정의함으로써 최고의 분류기를 선택하기가 더 명료해집니다.          
여기서는 분류기 B겠네요. 100ms보다 실행 시간이 짧은 것 중에 정확도가 가장 높으니까요.       
일반적으로 n개의 척도가 고려될 때 하나를 최적 척도로 골라서          
가능한 한 성능을 높이고 싶고 n-1개의 척도를 조건 척도로 둬서 실행 시간이 100ms보다.            
짧아야하는 것처럼 기준을 정하되 그 기준을 넘기만 하면 성능이 얼마나 좋든지 상관이 없다고 하는 겁니다.             

# 유발 단어 감지 시스템
![image](https://user-images.githubusercontent.com/50114210/68034979-10808500-fd06-11e9-8efe-c6540148309a.png)          
여기 다른 예시를 볼까요?
여러분이 유발 단어라고도 불리는 시작 단어를 감지하는 시스템을 만든다고 합시다.         
아마존 Echo에 Alexa나 구글 장치를 '오케이, 구글'이라고 불러 깨우는 것처럼 말이죠.        
애플 장치는 '시리야'라고 불러야 깨죠?       
바이두의 장치는 '니하오, 바이두'라고 불러야 합니다.         
이런 시작 단어를 이용해서 음성 인식 장치를 깨운 뒤 여러분이 말하고자 하는 것을 듣게 하는 거죠.          

### 정확도와 거짓 양성
![image](https://user-images.githubusercontent.com/50114210/68035124-56d5e400-fd06-11e9-96b5-10a4a2b83f46.png)        
여기서 유발 단어 감지 시스템의 정확도가 중요하겠죠?        
누군가가 이런 유발 단어를 말했을 때 여러분의 장치는 얼마나 잘 깨어날 수 있냐는 것이죠.           
거짓 양성도 중요하게 생각할 수 있습니다.         

### 최적화 척도, 조건 척도
![image](https://user-images.githubusercontent.com/50114210/68035138-5e958880-fd06-11e9-816d-e7eb50e126eb.png)     
유발 단어를 말하지 않은 경우에 장치가 일어나는 빈도가 얼마나 잦은가를 따지죠.         
이런 경우에 두 개의 평가 척도를 결합하는 합리적인 방법 중 하나는 정확도를 최대화하는 걸 겁니다.          
누군가가 유발 단어를 말했을 때 장치가 깨어날 확률을 높이는 것이죠.        
다만 24시간 동안 작동시켰을 때 최대 하나의 거짓 양성이 일어난다는 조건 하에서요.        
실제 말하지 않았는데 장치가 평균적으로 하루에 한 번 깨어나는 거죠.        
이런 경우에는 정확도가 최적 척도이고 24시간마다 일어나는 거짓 양성의 횟수가 조건 척도가 될 겁니다.         
매 24시간마다 최대 한 번의 긍정오류만 가능하다는 조건을 만족해야하니까요.       

# 아웃트로
요약하자면 많은 것들을 고려해야할 때 성능을 최대로 높이고 싶은 하나를           
최적 척도로 하고 어떤 기준만 넘기면 되도록 하나 이상을 조건 척도로 정함으로써         
거의 자동으로 여러 분류기를 살핀 뒤 빠르게 최고를 선별할 수 있습니다.          
여기서 이런 평가 척도들은 반드시 학습 세트, 개발 세트, 시험 세트에 대해 계산되어야 합니다.        
