---
layout: post
title: "잘못 라벨링된 데이터 해결하기"
tags: [Incorrectly labeled data, error analysis]
categories: [Structuring Machine Learning Projects]
---

# 학습 목표
라벨링이 잘못됐을 때 해결하는 방법을 알아본다.

# 핵심 키워드
* 잘못 라벨링 된 데이터(Incorrectly labeled data)
* 오차 분석(error analysis)

# 학습 내용
* 잘못 라벨링 된 데이터의 처리를 훈련, 개발, 시험 세트에 대해서 알아봅니다.
* 훈련 세트
  - 훈련세트는 무작위 오차에 대해 다소 둔감합니다. 잘못 라벨링 된 데이터의 학습 결과 오차가 무작위 오차와 크게 차이 나지 않을 경우 고치지 않아도 됩니다.
  - 하지만 무작위 오차가 아닌 시스템적인 오류(같은 라벨에 대해서 계속 오분류를 하는 것)는 덜 둔감하기 때문에 문제가 있습니다.
* 개발 및 시험 세트
  - 개발 및 시험 세트는 오차 분석시 잘못 라벨링으로 인한 오차의 비율을 구하시고, 전체 오차에서 얼만큼 차지하는지 살펴보고 결정하기를 권장합니다.
  - 개발과 시험 세트의 분포는 같아야하기 때문에 동시에 살펴 볼 것을 권장합니다.

# 인트로
지도 학습 문제를 위한 데이터는 입력값 X와 출력 라벨 Y로 구성되어 있습니다.           
데이터를 다루던 중에 출력 라벨 Y의 일부가 옳지 않은 걸 확인했습니다.            
잘못 라벨링된 것이죠. 이 라벨들을 옳게 고치는 것이 가치있는 일일까요?          

# 잘못 라벨링된 데이터
![image](https://user-images.githubusercontent.com/50114210/68950412-7806fc00-07ff-11ea-9d6e-53e12a743532.png)         
고양이 분류 문제에서 y는 고양이면 1 아니면 0의 값을 갖습니다.           
잘못된 라벨의 예시입니다. 러닝 알고리즘에서 이렇게 라벨의 값이 잘못된 경우          
일반적으로 잘못 라벨링되었다고 말을 하는데요.            
하지만 저는 잘못 라벨링되었다는 것을 학습 세트, 개발 세트, 시험 세트 등           
데이터 세트에 대해서 사람이 잘못 라벨링한 경우를 말할 때도 사용할 겁니다.           
이건 실제로 개이기 때문에 y값이 0이 되어야 겠죠. 하지만 라벨링이 잘못 이루어졌습니다.        

# 어쩌다가 잘못 라벨링된 데이터는 놔둬도 괜찮지만 계속 그러는건 안 됨
![image](https://user-images.githubusercontent.com/50114210/68950457-8c4af900-07ff-11ea-9fc5-c939cc3e56ae.png)       
이렇게 잘못 라벨링된 예시를 찾았다면 어떻게 해야할까요? 우선 학습 세트에 대해 생각해봅시다.      
딥러닝 알고리즘은 학습 세트의 무작위 오차에 대해 다소 둔감하다는 것이 밝혀졌습니다.          
즉 잘못 라벨링된 예시의 오차가 무작위 오차와 큰 차이가 나지 않을 경우          
예를 들어 집중이 잠시 흐트러졌거나 우연히 잘못된 키보드를 쳤을 수도 있겠죠.        
즉 합리적으로 무작위한 오차일 때 그냥 오차를 놔두는 것도 괜찮습니다.         
그런 오차를 고치는데 시간을 많이 쓸 필요가 없는 것이죠.           
물론 학습 세트의 라벨을 살펴보고 잘못된 것을 고치는 것이 때때로 쓸모 있지만              
데이터가 충분히 많은 한 그냥 놔둬도 알고리즘에 큰 영향은 없습니다.         
실제 오차가 그렇게 크지 않을 거거든요 저도 학습 세트에 몇 가지 오류가 있는             
머신 러닝 알고리즘을 많이 봤지만 큰 문제는 없었습니다.         
단 주의할 점이 하나 있는데요. 딥러닝 알고리즘은 무작위 오차에 대해서만 둔감하다는 겁니다.             
즉 구조적인 오차에 대해서는 덜 둔감합니다.         
예를 들어 여러분이 계속해서 흰 개를 고양이로 분류했다면 그건 문제입니다.          
왜냐하면 여러분의 분류기가 모든 흰 개를 고양이로 분류할 것이기 때문이죠.            
하지만 무작위 또는 그에 가까운 오류는 딥러닝 알고리즘 대부분에 큰 악영향을 끼치지 않습니다.           

# 오차 분석에서 하나의 열을 
![image](https://user-images.githubusercontent.com/50114210/68951355-324b3300-0801-11ea-941e-5a06069833c7.png)        
지금까지 학습 세트에서 잘못 라벨링된 예시들을 어떻게 다뤄야할지 얘기하고 있는데요.           
그렇다면 개발 세트나 학습 세트에서 잘못 라벨링된 예시들은 어떨까요?           
만약 개발 세트와 학습 세트에서 잘못 라벨링된 예시들이 끼칠 악영향을 우려하고 계신다면               
오차 분석에서 하나의 열을 추가하기를 권장해드립니다. 잘못된 라벨 y의 개수를 세는 것이죠.             
예를 들어 100개의 잘못 라벨링된 개발 세트 예시들을 헤아릴 때      
즉 개발 세트에서 분류기의 결과와 라벨이 일치하지 않는 100개의 예시에 대해서        
몇 개의 예시들은 아마 라벨 자체가 잘못 되었을 겁니다.           
분류기가 잘못된 것이 아니구요. 이 경우는 배경에 그려진 고양이를 확인하지 못 했네요.           
그래서 체크 표시를 해서 98번 예시의 라벨이 잘못되었음을 표시합니다.           
그리고 이 경우는 실제 고양이가 아니라 그림이 있었네요.          
그래서 y를 0으로 라벨링했지만 정답은 1일 겁니다. 따라서 체크 표시를 해야겠죠.            
그리고 지난 영상에서 다른 카테고리로 인한
오류 퍼센트를 계산한 것처럼 잘못된 라벨으로 인한 오류의 퍼센트도 계산합니다.           
개발 세트에서의 y값이 잘못 되어서 러닝 알고리즘의 예측이 실제 데이터의 라벨과 달라진 경우죠.           

# 라벨을 고치는 것이 의미가 있을지 
![image](https://user-images.githubusercontent.com/50114210/68951395-4a22b700-0801-11ea-9540-4cefde88daea.png)        
여기서 질문은 이걸 고치는게 쓸모가 있을까 하는 겁니다.            
여기 6%의 잘못 라벨링된 예시를 말이죠.        
제 생각에는 만약 이게 개발 세트를 이용하여 알고리즘을 평가하는데            
막대한 영향을 끼친다면 곧장 잘못된 라벨을 고치기 위해 시간을 써야할 것 같습니다.         
만약 개발 세트를 이용하여 분류기를 평가할 때 큰 차이가 없을 경우 시간을 안 쓰는 것이 좋겠죠.         

# 오류의 비율 중 큰 비율을 차지하고 있지 않다면 수정하지 않음
제가 뭘 설명하고 있는지를 묘사하는 예시를 하나 보여드리죠.          
잘못 라벨링된 예시의 숫자를 줄이기 위해 손보는 것이 가치있는지를 판단하기 위해 세 가지 숫자가 중요합니다.            
우선 전체 개발 세트 오차를 보시길 추천하고요 지난 영상에서 봤던 것처럼         
우리의 예시는 전체적으로 정확도가 90%에 달하니 오차는 10%입니다.           
그리고 잘못된 라벨으로 인한 오차의 비율을 봐야 합니다.            
여기에서 6%의 오류가 잘못된 라벨 때문에 발생한 것이니 10%의 6%, 즉 0.6%가 되겠네요.           
그리고 그밖의 이유로 발생하는 오류도 봐야 합니다.          
개발 세트에서 10%의 오류를 일으켰고 0.6%가 잘못된 라벨 때문에 일어났다면             
나머지 9.4%가 개, 거대한 고양이류 동물 흐릿한 사진 등 다른 이유로 일어났겠죠.          
이런 경우에는 9.4%의 오류에 초점을 맞추라고 말하고 싶습니다.            
잘못된 라벨으로 인한 오류는 전체 오류 중에 작은 부분만을 차지하니까요.              
물론 원한다면 잘못된 라벨을 고치는 것도 좋지만 지금 해야 할 가장 중요한 일은 아닙니다.            

# 오류의 비율 중 큰 비율을 차지하고 있다면 수정
![image](https://user-images.githubusercontent.com/50114210/68951422-59096980-0801-11ea-8976-28cc350e64cc.png)                     
다른 예시도 하나 살펴보죠 학습 문제에 많은 진전이 있어서 오류가 10% 대신 2%로 줄었다고 합시다.          
전체 오류의 0.6%가 잘못된 라벨 때문이고요.        
이제 전체 개발 세트 사진 중에 잘못 라벨링된 사진의 비율을 볼까요?          
2%에 대하여 아주 큰 비율인 0.6%를 차지합니다.          
0.6%을 2%로 나누면 잘못된 라벨으로 인한 오류의 비율이 6%가 아닌 30%에 가까운 수치가 나옵니다.           
그러면 다른 이유 때문에 발생하는 오류는 1.4%가 되는 거죠.         
이처럼 오류의 큰 비율이 잘못된 라벨에 의해 발생했다면         
개발 세트의 잘못된 라벨을 고치는 시간이 더욱 가치를 갖게 됩니다.          

# 개발 세트의 확률을 신뢰할 수 있는지 확인하자
![image](https://user-images.githubusercontent.com/50114210/68951468-79d1bf00-0801-11ea-948a-f0e29f05e39d.png)          
여기서 개발 세트의 주목적을 떠올려보자면 두 개의 분류기 A와 B 중 하나를 선택하기 위함이었습니다.           
두 개의 분류기 A, B가 있을 때 개발 세트에 대하여 하나는 2.1% 다른 하나는 1.9%의 오차를 보인다면
그러나 잘못된 라벨으로 인한 0.6%의 오류때문에 개발 세트가 더 나은 분류기를          
말해주리라고 믿지 못한다면 개발 세트의 잘못된 라벨을 고치면 됩니다.               
왜냐하면 오른쪽의 예시에서는 알고리즘의 오차가 알고리즘을 평가하는데 아주 큰 영향을 끼치기 때문입니다.           
반면 왼쪽의 예시에서는 %로 본 알고리즘에의 영향이 적지만요.        

# 개발세트와 테스트세트를 함께 수정하자
![image](https://user-images.githubusercontent.com/50114210/68951538-a84f9a00-0801-11ea-88f9-94dbc184d11e.png)          
만약 개발 세트의 라벨들을 고치기로 마음먹었다면 여러분이 고려해야 할 가이드라인을 참고하기 바랍니다.          
우선 개발 세트와 시험 세트에 대해 동일한 과정을 동시에 적용하기 바랍니다.         
이전에 개발 세트와 시험 세트가 왜 같은 분포에서 나오는지 얘기했습니다.           
개발 세트는 여러분이 목표로 하는 곳이 어디인지를 알려줘서 그걸 달성하면              
시험 세트로 일반화를 할 수 있는 것이죠.         
따라서 개발 세트와 시험 세트가 동일한 분포에서 얻어진다면 더 효율적으로 작업할 수 있는 겁니다.           
즉 개발 세트를 고치신다면 시험 세트도 마찬가지로 고칠 겁니다.            
왜냐하면 두 개가 같은 분포에서 얻어져야하기 때문이죠.            
즉 누군가를 고용해서 라벨링을 다시 한다면 개발 세트와 시험 세트 모두에 대해 시키세요.            

# 맞은 경우도 확인하자
![image](https://user-images.githubusercontent.com/50114210/68951563-b3a2c580-0801-11ea-9c8d-c8995b9468b2.png)         
알고리즘이 틀린 예시 뿐만 아니라 맞은 예시들도 살펴보기를 추천합니다.          
틀린 예시들을 살펴보고 고쳐야할 것이 있는지 검사하는 건 쉽습니다.          
그러나 맞았지만 고쳐져야 하는 예시들도 있을 수 있습니다.           
만약 틀린 것만 고친다면 알고리즘의 오차 추정치는 더 큰 편향을 보일 겁니다.           
즉 알고리즘에 불공평한 혜택을 주는 것이죠.             
틀린 것만 확인하고 맞은 것은 확인하지 않는다면 말입니다.            
왜냐하면 행운으로 맞았을 수도 있기 때문에 라벨을 고침으로써 정답이 오답으로 바뀔 수도 있으니까요.         
두 번째 문장은 쉽지 않기 때문에 항상 하지는 않습니다.          
다시 말해 만약 분류기가 정말 정확해서 정답이 오답보다 훨씬 많다면           
즉 98% 정도의 정확도를 보인다면 2%는 오답이고 98%는 정답인 셈이죠.          
그러면 2%의 데이터에 대한 라벨을 확인하고 검증하는 것이 더 쉬울테니까요.         
그리고 98%의 데이터의 라벨을 확인하는 작업은 훨씬 오래 걸릴 겁니다.        
그래서 항상 할 수는 없죠. 하지만 고려해볼만한 요소입니다.             

# 학습 데이터의 분포가 조금은 달라도 괜찮다
![image](https://user-images.githubusercontent.com/50114210/68951586-bef5f100-0801-11ea-8503-f3874311e71d.png)         
끝으로 라벨을 고치기 위해서 개발, 시험 세트를 다루기 시작했다면       
학습 세트에 대해서는 같은 과정을 적용할 수도 적용하지 않을 수도 있습니다.         
이 영상에서 학습 세트의 라벨을 고치는 것은 덜 중요하다고 한 것 기억하나요?           
개발, 시험 세트의 라벨만 옳게 고치는 것도 가능한 이야기입니다. 학습 세트보다 크기가 작은 세트들이죠.          
그리고 훨씬 큰 학습 세트의 라벨을 고치기 위해 추가적인 수고를 반드시 하실 필요는 없습니다.            
대신 개발, 시험 세트가 같은 분포에서 얻어져야 하는 것이 훨씬 중요하죠.            
그러나 학습 세트가 다른 분포에서 얻어지는 것은 합리적인 경우일 때가 많습니다.          

# 아웃트로
몇 가지 조언으로 마무리하도록 하겠습니다.         
우선 딥러닝 연구자들은 알고리즘에 데이터를 줬더니 학습해서 작동한다고 말하는 걸 좋아합니다.            
딥러닝의 역사에서 그 말은 점점 사실이 되었죠.    
점점 데이터를 주고 학습시키는 데 초점이 주어진 반면 사람의 손은 덜 필요해졌고 직관 역시 마찬가지였습니다.             
하지만 실용적인 시스템을 만들 때에는 직접 오차 분석도 해야하고 더 많은 직관을 필요로 합니다.        
이건 딥러닝 연구자들도 인정하는 바죠 다음으로 일부 공학자, 연구자들이 직접 예시를 살펴보는 것을 꺼리곤 합니다.          
물론 앉아서 100개, 200개나 되는 예시를 보고 오류의 개수를 세는 일이 결코 흥미로운 일은 아니죠.       
하지만 제가 머신러닝 팀을 이끌 때 어떤 실수가 있는지 확인하기 위해서 저도 스스로 하는 일입니다.      
직접 데이터를 살펴보고 오류의 비율을 헤아리죠.           
왜냐하면 수 분에서 몇 시간 동안 데이터를 헤아리면서 다음으로 할 일의 우선 순위를 정할 수 있기 때문이죠.           
따라서 만약 머신러닝 시스템을 만들고 있다면 이 방법을 이용해 시간을 효율적으로 쓰시기 바랍니다.         
그리고 어떤 아이디어, 방향에 우선순위를 둬야할지 정할 수도 있고요.        
